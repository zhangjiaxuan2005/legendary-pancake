{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RNN 文本生成实战",
   "id": "3bea97e5c749088"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 手写RNN\n",
    "RNN公式：$$ h_t = \\tanh(W_{ih}x_t + b_{ih} + W_{hh}h_{t-1} + b_{hh}) $$"
   ],
   "id": "188630a85046c7e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class XuanRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        #初始化参数\n",
    "        self.W_ih = nn.Parameter(torch.randn(input_size, batch_size))\n",
    "        self.W_hh = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "        self.b_h = nn.Parameter(torch.randn(hidden_size))\n",
    "\n",
    "        self.hidden = None\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, input_size = x.shape\n",
    "\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "\n",
    "        self.hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        hidden_states = []\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[t]\n",
    "            # 计算当前时间步的隐藏状态\n",
    "            self.hidden = torch.tanh(\n",
    "                torch.mm(x_t, self.W_ih) +\n",
    "                torch.mm(self.hidden, self.W_hh) +\n",
    "                self.b_h\n",
    "            )\n",
    "            hidden_states.append(self.hidden)\n",
    "\n",
    "        return torch.stack(hidden_states), self.hidden\n",
    "\n",
    "\n",
    "input_size = 3\n",
    "hidden_size = 2\n",
    "seq_len = 4\n",
    "batch_size = 1\n",
    "\n",
    "rnn = XuanRNN(input_size, hidden_size)\n",
    "x = torch.randn(batch_size, seq_len, input_size)\n",
    "print(x)"
   ],
   "id": "f5f811f2e85262fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "output, hidden = rnn(x)\n",
    "print(output)\n",
    "print(hidden)"
   ],
   "id": "7225977fae19ed49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T03:56:54.859635Z",
     "start_time": "2025-07-14T03:56:54.849452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"\"\"\n",
    "臣密言：臣以险衅，夙遭闵凶。生孩六月，慈父见背；行年四岁，舅夺母志。\n",
    "祖母刘愍臣孤弱，躬亲抚养。\n",
    "臣少多疾病，九岁不行，零丁孤苦，至于成立。\n",
    "既无伯叔，终鲜兄弟，门衰祚薄，晚有儿息。\n",
    "外无期功强近之亲，内无应门五尺之僮，茕茕孑立，形影相吊。\n",
    "而刘夙婴疾病，常在床蓐，臣侍汤药，未曾废离。\n",
    "\"\"\"\n",
    "\n",
    "words = set(text)\n",
    "vocab_size = len(words)\n",
    "word_to_index = {word: i for i, word in enumerate(words)}\n",
    "index_to_word = {i: word for i, word in enumerate(words)}\n",
    "\n",
    "print(word_to_index)"
   ],
   "id": "bd87d0466f0213db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'相': 0, '在': 1, '既': 2, '孤': 3, '强': 4, '内': 5, '药': 6, '无': 7, '应': 8, '五': 9, '功': 10, '孩': 11, '父': 12, '息': 13, '至': 14, '苦': 15, '叔': 16, '抚': 17, '终': 18, '侍': 19, '床': 20, '舅': 21, '伯': 22, '六': 23, '茕': 24, '祚': 25, '有': 26, '年': 27, '岁': 28, '常': 29, '亲': 30, '；': 31, '儿': 32, '，': 33, '而': 34, '志': 35, '成': 36, '薄': 37, '夙': 38, '汤': 39, '僮': 40, '之': 41, '影': 42, '尺': 43, '夺': 44, '言': 45, '未': 46, '曾': 47, '以': 48, '背': 49, '晚': 50, '凶': 51, '形': 52, '衅': 53, '密': 54, '见': 55, '祖': 56, '慈': 57, '四': 58, '母': 59, '。': 60, '期': 61, '鲜': 62, '孑': 63, '愍': 64, '\\n': 65, '不': 66, '少': 67, '兄': 68, '弟': 69, '蓐': 70, '养': 71, '遭': 72, '离': 73, '衰': 74, '吊': 75, '闵': 76, '零': 77, '：': 78, '外': 79, '立': 80, '疾': 81, '生': 82, '弱': 83, '病': 84, '近': 85, '险': 86, '于': 87, '刘': 88, '废': 89, '多': 90, '丁': 91, '婴': 92, '九': 93, '月': 94, '行': 95, '臣': 96, '躬': 97, '门': 98}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T03:57:05.601387Z",
     "start_time": "2025-07-14T03:57:02.236425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "SEQ_LEN = 5\n",
    "BATCH_SIZE = 1\n",
    "HIDDEN_SIZE = 128\n",
    "EMBEDDING_SIZE = 128\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text, seq_len):\n",
    "        self.text = text\n",
    "        self.seq_len = seq_len\n",
    "        self.data = [word_to_index[ch] for ch in text]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_seq = self.data[index:index + self.seq_len]\n",
    "        target_seq = self.data[index + 1:index + self.seq_len + 1]\n",
    "        return torch.tensor(input_seq), torch.tensor(target_seq)\n",
    "\n",
    "\n",
    "dataset = TextDataset(text, SEQ_LEN)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print(dataset.data)"
   ],
   "id": "a36c2582ebc0e51c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65, 96, 54, 45, 78, 96, 48, 86, 53, 33, 38, 72, 76, 51, 60, 82, 11, 23, 94, 33, 57, 12, 55, 49, 31, 95, 27, 58, 28, 33, 21, 44, 59, 35, 60, 65, 56, 59, 88, 64, 96, 3, 83, 33, 97, 30, 17, 71, 60, 65, 96, 67, 90, 81, 84, 33, 93, 28, 66, 95, 33, 77, 91, 3, 15, 33, 14, 87, 36, 80, 60, 65, 2, 7, 22, 16, 33, 18, 62, 68, 69, 33, 98, 74, 25, 37, 33, 50, 26, 32, 13, 60, 65, 79, 7, 61, 10, 4, 85, 41, 30, 33, 5, 7, 8, 98, 9, 43, 41, 40, 33, 24, 24, 63, 80, 33, 52, 42, 0, 75, 60, 65, 34, 88, 38, 92, 81, 84, 33, 29, 1, 20, 70, 33, 96, 19, 39, 6, 33, 46, 47, 89, 73, 60, 65]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for input_seq, target_seq in train_loader:\n",
    "    print(input_seq)\n",
    "    print(target_seq)\n",
    "    break"
   ],
   "id": "c946cc8c39ce5bd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 定义模型",
   "id": "c628421eed17df49"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class XuanRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        #定义词嵌入层\n",
    "        self.embedding = nn.Embedding(vocab_size, input_size)\n",
    "\n",
    "        #初始化参数\n",
    "        self.W_ih = nn.Parameter(torch.randn(input_size, hidden_size))\n",
    "        self.W_hh = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "        self.b_h = nn.Parameter(torch.randn(hidden_size))\n",
    "\n",
    "        self.Out_Linear = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "\n",
    "        embedded = self.embedding(x)\n",
    "        batch_size, seq_len, input_size = embedded.shape\n",
    "        embedded = torch.transpose(embedded, 0, 1)\n",
    "\n",
    "        if hidden is None:\n",
    "            hidden = torch.zeros(batch_size, self.hidden_size)\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            x_t = embedded[t]\n",
    "            # 计算当前时间步的隐藏状态\n",
    "            hidden = torch.tanh(\n",
    "                torch.mm(x_t, self.W_ih) +\n",
    "                torch.mm(hidden, self.W_hh) +\n",
    "                self.b_h\n",
    "            )\n",
    "            outputs.append(self.Out_Linear(hidden))\n",
    "\n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "        return outputs, hidden"
   ],
   "id": "ff6bd3c6d5671f9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = XuanRNN(vocab_size, EMBEDDING_SIZE, HIDDEN_SIZE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(100):\n",
    "    for i, (input_seq, target_seq) in enumerate(train_loader):\n",
    "        output, _ = model(input_seq)\n",
    "        loss = criterion(\n",
    "            output.view(-1, vocab_size),\n",
    "            target_seq.view(-1)\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        if i % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/100], Step [{i + 10}/{len(train_loader)}], Loss: {loss.item():.4f}')"
   ],
   "id": "6a7fed557e8ce88f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "\n",
    "\n",
    "def generate_text(context, step, temperature=0.8):\n",
    "    words = [word for word in context]\n",
    "    hidden = None\n",
    "    for _ in range(step):\n",
    "        input_seq = torch.tensor([word_to_index[word] for word in words[-1:]])\n",
    "        input_seq = torch.LongTensor(input_seq)\n",
    "        input_seq = input_seq.view(1, -1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hidden = model(input_seq, hidden)\n",
    "            last_output = output[0, -1, :]\n",
    "            probs = torch.softmax(last_output / temperature, dim=-1)\n",
    "            result_index = torch.multinomial(probs, 1).item()\n",
    "            result = index_to_word[result_index]\n",
    "            words.append(result)\n",
    "    return ''.join(words)\n",
    "\n",
    "\n",
    "print(generate_text('臣密言：', 5, 0.1))"
   ],
   "id": "c50fc358618c3f3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### pytorch RNN",
   "id": "7a0c55bdea3d050c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T04:02:20.962336Z",
     "start_time": "2025-07-14T04:02:20.952826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out_linear = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        embedding = self.embedding(x)\n",
    "        outputs, hidden = self.rnn(embedding, hidden)\n",
    "        outputs = self.out_linear(outputs)\n",
    "        return outputs, hidden\n"
   ],
   "id": "f03ae8815cdce812",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T04:03:40.361186Z",
     "start_time": "2025-07-14T04:02:23.593761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = RNN(vocab_size, EMBEDDING_SIZE, HIDDEN_SIZE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(100):\n",
    "    for i, (input_seq, target_seq) in enumerate(train_loader):\n",
    "        output, _ = model(input_seq)\n",
    "        loss = criterion(\n",
    "            output.view(-1, vocab_size),\n",
    "            target_seq.view(-1)\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        if i % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/100], Step [{i + 10}/{len(train_loader)}], Loss: {loss.item():.4f}')"
   ],
   "id": "b72cde0e378d2531",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [10/140], Loss: 4.6556\n",
      "Epoch [1/100], Step [20/140], Loss: 4.7749\n",
      "Epoch [1/100], Step [30/140], Loss: 4.0097\n",
      "Epoch [1/100], Step [40/140], Loss: 4.1328\n",
      "Epoch [1/100], Step [50/140], Loss: 3.3954\n",
      "Epoch [1/100], Step [60/140], Loss: 3.8861\n",
      "Epoch [1/100], Step [70/140], Loss: 3.6354\n",
      "Epoch [1/100], Step [80/140], Loss: 3.2553\n",
      "Epoch [1/100], Step [90/140], Loss: 2.9739\n",
      "Epoch [1/100], Step [100/140], Loss: 2.6875\n",
      "Epoch [1/100], Step [110/140], Loss: 2.6058\n",
      "Epoch [1/100], Step [120/140], Loss: 2.2229\n",
      "Epoch [1/100], Step [130/140], Loss: 2.6014\n",
      "Epoch [1/100], Step [140/140], Loss: 2.6199\n",
      "Epoch [2/100], Step [10/140], Loss: 1.8955\n",
      "Epoch [2/100], Step [20/140], Loss: 1.6531\n",
      "Epoch [2/100], Step [30/140], Loss: 1.1175\n",
      "Epoch [2/100], Step [40/140], Loss: 1.5310\n",
      "Epoch [2/100], Step [50/140], Loss: 2.3577\n",
      "Epoch [2/100], Step [60/140], Loss: 1.1428\n",
      "Epoch [2/100], Step [70/140], Loss: 1.5352\n",
      "Epoch [2/100], Step [80/140], Loss: 1.6164\n",
      "Epoch [2/100], Step [90/140], Loss: 1.2225\n",
      "Epoch [2/100], Step [100/140], Loss: 0.7490\n",
      "Epoch [2/100], Step [110/140], Loss: 0.8766\n",
      "Epoch [2/100], Step [120/140], Loss: 1.3897\n",
      "Epoch [2/100], Step [130/140], Loss: 0.7781\n",
      "Epoch [2/100], Step [140/140], Loss: 0.4417\n",
      "Epoch [3/100], Step [10/140], Loss: 0.5432\n",
      "Epoch [3/100], Step [20/140], Loss: 0.3445\n",
      "Epoch [3/100], Step [30/140], Loss: 0.4784\n",
      "Epoch [3/100], Step [40/140], Loss: 0.7285\n",
      "Epoch [3/100], Step [50/140], Loss: 0.8720\n",
      "Epoch [3/100], Step [60/140], Loss: 0.7148\n",
      "Epoch [3/100], Step [70/140], Loss: 0.4522\n",
      "Epoch [3/100], Step [80/140], Loss: 0.2745\n",
      "Epoch [3/100], Step [90/140], Loss: 0.4773\n",
      "Epoch [3/100], Step [100/140], Loss: 0.4142\n",
      "Epoch [3/100], Step [110/140], Loss: 0.8056\n",
      "Epoch [3/100], Step [120/140], Loss: 0.6630\n",
      "Epoch [3/100], Step [130/140], Loss: 0.4885\n",
      "Epoch [3/100], Step [140/140], Loss: 0.3682\n",
      "Epoch [4/100], Step [10/140], Loss: 0.2126\n",
      "Epoch [4/100], Step [20/140], Loss: 0.4582\n",
      "Epoch [4/100], Step [30/140], Loss: 0.8173\n",
      "Epoch [4/100], Step [40/140], Loss: 0.1390\n",
      "Epoch [4/100], Step [50/140], Loss: 0.1914\n",
      "Epoch [4/100], Step [60/140], Loss: 0.0760\n",
      "Epoch [4/100], Step [70/140], Loss: 0.2006\n",
      "Epoch [4/100], Step [80/140], Loss: 0.5013\n",
      "Epoch [4/100], Step [90/140], Loss: 0.6129\n",
      "Epoch [4/100], Step [100/140], Loss: 0.0404\n",
      "Epoch [4/100], Step [110/140], Loss: 0.5878\n",
      "Epoch [4/100], Step [120/140], Loss: 0.6224\n",
      "Epoch [4/100], Step [130/140], Loss: 0.1950\n",
      "Epoch [4/100], Step [140/140], Loss: 0.1141\n",
      "Epoch [5/100], Step [10/140], Loss: 0.1461\n",
      "Epoch [5/100], Step [20/140], Loss: 0.0555\n",
      "Epoch [5/100], Step [30/140], Loss: 0.6908\n",
      "Epoch [5/100], Step [40/140], Loss: 0.7398\n",
      "Epoch [5/100], Step [50/140], Loss: 0.1308\n",
      "Epoch [5/100], Step [60/140], Loss: 0.0766\n",
      "Epoch [5/100], Step [70/140], Loss: 1.2816\n",
      "Epoch [5/100], Step [80/140], Loss: 0.7641\n",
      "Epoch [5/100], Step [90/140], Loss: 0.8462\n",
      "Epoch [5/100], Step [100/140], Loss: 0.5615\n",
      "Epoch [5/100], Step [110/140], Loss: 0.0693\n",
      "Epoch [5/100], Step [120/140], Loss: 0.0269\n",
      "Epoch [5/100], Step [130/140], Loss: 0.5395\n",
      "Epoch [5/100], Step [140/140], Loss: 0.0422\n",
      "Epoch [6/100], Step [10/140], Loss: 0.0602\n",
      "Epoch [6/100], Step [20/140], Loss: 0.1681\n",
      "Epoch [6/100], Step [30/140], Loss: 0.6840\n",
      "Epoch [6/100], Step [40/140], Loss: 0.2370\n",
      "Epoch [6/100], Step [50/140], Loss: 0.5615\n",
      "Epoch [6/100], Step [60/140], Loss: 0.7336\n",
      "Epoch [6/100], Step [70/140], Loss: 0.6944\n",
      "Epoch [6/100], Step [80/140], Loss: 0.4391\n",
      "Epoch [6/100], Step [90/140], Loss: 0.4881\n",
      "Epoch [6/100], Step [100/140], Loss: 0.0237\n",
      "Epoch [6/100], Step [110/140], Loss: 0.7279\n",
      "Epoch [6/100], Step [120/140], Loss: 0.5119\n",
      "Epoch [6/100], Step [130/140], Loss: 0.0299\n",
      "Epoch [6/100], Step [140/140], Loss: 0.1666\n",
      "Epoch [7/100], Step [10/140], Loss: 0.0197\n",
      "Epoch [7/100], Step [20/140], Loss: 0.0163\n",
      "Epoch [7/100], Step [30/140], Loss: 0.4621\n",
      "Epoch [7/100], Step [40/140], Loss: 0.3193\n",
      "Epoch [7/100], Step [50/140], Loss: 0.0235\n",
      "Epoch [7/100], Step [60/140], Loss: 0.0401\n",
      "Epoch [7/100], Step [70/140], Loss: 0.3464\n",
      "Epoch [7/100], Step [80/140], Loss: 0.1621\n",
      "Epoch [7/100], Step [90/140], Loss: 0.0186\n",
      "Epoch [7/100], Step [100/140], Loss: 0.0197\n",
      "Epoch [7/100], Step [110/140], Loss: 0.0292\n",
      "Epoch [7/100], Step [120/140], Loss: 0.0214\n",
      "Epoch [7/100], Step [130/140], Loss: 0.5542\n",
      "Epoch [7/100], Step [140/140], Loss: 0.5301\n",
      "Epoch [8/100], Step [10/140], Loss: 0.0212\n",
      "Epoch [8/100], Step [20/140], Loss: 0.1894\n",
      "Epoch [8/100], Step [30/140], Loss: 0.6404\n",
      "Epoch [8/100], Step [40/140], Loss: 0.0124\n",
      "Epoch [8/100], Step [50/140], Loss: 0.0641\n",
      "Epoch [8/100], Step [60/140], Loss: 0.0228\n",
      "Epoch [8/100], Step [70/140], Loss: 0.0920\n",
      "Epoch [8/100], Step [80/140], Loss: 0.0554\n",
      "Epoch [8/100], Step [90/140], Loss: 0.2000\n",
      "Epoch [8/100], Step [100/140], Loss: 0.0147\n",
      "Epoch [8/100], Step [110/140], Loss: 0.7387\n",
      "Epoch [8/100], Step [120/140], Loss: 0.0171\n",
      "Epoch [8/100], Step [130/140], Loss: 0.6138\n",
      "Epoch [8/100], Step [140/140], Loss: 1.0090\n",
      "Epoch [9/100], Step [10/140], Loss: 0.0171\n",
      "Epoch [9/100], Step [20/140], Loss: 0.3257\n",
      "Epoch [9/100], Step [30/140], Loss: 0.1167\n",
      "Epoch [9/100], Step [40/140], Loss: 0.0130\n",
      "Epoch [9/100], Step [50/140], Loss: 0.0123\n",
      "Epoch [9/100], Step [60/140], Loss: 0.0139\n",
      "Epoch [9/100], Step [70/140], Loss: 0.0092\n",
      "Epoch [9/100], Step [80/140], Loss: 0.0127\n",
      "Epoch [9/100], Step [90/140], Loss: 0.2353\n",
      "Epoch [9/100], Step [100/140], Loss: 0.0344\n",
      "Epoch [9/100], Step [110/140], Loss: 0.6556\n",
      "Epoch [9/100], Step [120/140], Loss: 0.7260\n",
      "Epoch [9/100], Step [130/140], Loss: 0.1917\n",
      "Epoch [9/100], Step [140/140], Loss: 0.0119\n",
      "Epoch [10/100], Step [10/140], Loss: 0.5377\n",
      "Epoch [10/100], Step [20/140], Loss: 0.0074\n",
      "Epoch [10/100], Step [30/140], Loss: 0.2224\n",
      "Epoch [10/100], Step [40/140], Loss: 0.0390\n",
      "Epoch [10/100], Step [50/140], Loss: 0.0108\n",
      "Epoch [10/100], Step [60/140], Loss: 0.0207\n",
      "Epoch [10/100], Step [70/140], Loss: 0.0653\n",
      "Epoch [10/100], Step [80/140], Loss: 0.0396\n",
      "Epoch [10/100], Step [90/140], Loss: 0.0136\n",
      "Epoch [10/100], Step [100/140], Loss: 0.0725\n",
      "Epoch [10/100], Step [110/140], Loss: 0.2026\n",
      "Epoch [10/100], Step [120/140], Loss: 0.7810\n",
      "Epoch [10/100], Step [130/140], Loss: 0.0101\n",
      "Epoch [10/100], Step [140/140], Loss: 0.2179\n",
      "Epoch [11/100], Step [10/140], Loss: 0.0081\n",
      "Epoch [11/100], Step [20/140], Loss: 0.6315\n",
      "Epoch [11/100], Step [30/140], Loss: 0.0073\n",
      "Epoch [11/100], Step [40/140], Loss: 0.1956\n",
      "Epoch [11/100], Step [50/140], Loss: 0.0103\n",
      "Epoch [11/100], Step [60/140], Loss: 0.0089\n",
      "Epoch [11/100], Step [70/140], Loss: 0.1121\n",
      "Epoch [11/100], Step [80/140], Loss: 0.0096\n",
      "Epoch [11/100], Step [90/140], Loss: 0.5240\n",
      "Epoch [11/100], Step [100/140], Loss: 0.0522\n",
      "Epoch [11/100], Step [110/140], Loss: 0.0166\n",
      "Epoch [11/100], Step [120/140], Loss: 0.1966\n",
      "Epoch [11/100], Step [130/140], Loss: 0.6983\n",
      "Epoch [11/100], Step [140/140], Loss: 0.0057\n",
      "Epoch [12/100], Step [10/140], Loss: 0.1081\n",
      "Epoch [12/100], Step [20/140], Loss: 0.0080\n",
      "Epoch [12/100], Step [30/140], Loss: 0.1264\n",
      "Epoch [12/100], Step [40/140], Loss: 0.0065\n",
      "Epoch [12/100], Step [50/140], Loss: 0.0067\n",
      "Epoch [12/100], Step [60/140], Loss: 0.0422\n",
      "Epoch [12/100], Step [70/140], Loss: 0.6550\n",
      "Epoch [12/100], Step [80/140], Loss: 0.0135\n",
      "Epoch [12/100], Step [90/140], Loss: 0.4898\n",
      "Epoch [12/100], Step [100/140], Loss: 0.0083\n",
      "Epoch [12/100], Step [110/140], Loss: 0.5344\n",
      "Epoch [12/100], Step [120/140], Loss: 0.5258\n",
      "Epoch [12/100], Step [130/140], Loss: 0.0059\n",
      "Epoch [12/100], Step [140/140], Loss: 0.5421\n",
      "Epoch [13/100], Step [10/140], Loss: 0.0054\n",
      "Epoch [13/100], Step [20/140], Loss: 0.0058\n",
      "Epoch [13/100], Step [30/140], Loss: 0.7768\n",
      "Epoch [13/100], Step [40/140], Loss: 0.0066\n",
      "Epoch [13/100], Step [50/140], Loss: 0.0121\n",
      "Epoch [13/100], Step [60/140], Loss: 0.3227\n",
      "Epoch [13/100], Step [70/140], Loss: 0.5748\n",
      "Epoch [13/100], Step [80/140], Loss: 0.0223\n",
      "Epoch [13/100], Step [90/140], Loss: 0.0517\n",
      "Epoch [13/100], Step [100/140], Loss: 0.0199\n",
      "Epoch [13/100], Step [110/140], Loss: 0.0040\n",
      "Epoch [13/100], Step [120/140], Loss: 0.7239\n",
      "Epoch [13/100], Step [130/140], Loss: 0.7582\n",
      "Epoch [13/100], Step [140/140], Loss: 0.6387\n",
      "Epoch [14/100], Step [10/140], Loss: 0.0056\n",
      "Epoch [14/100], Step [20/140], Loss: 0.0116\n",
      "Epoch [14/100], Step [30/140], Loss: 0.2359\n",
      "Epoch [14/100], Step [40/140], Loss: 0.0795\n",
      "Epoch [14/100], Step [50/140], Loss: 0.0030\n",
      "Epoch [14/100], Step [60/140], Loss: 0.0133\n",
      "Epoch [14/100], Step [70/140], Loss: 0.0168\n",
      "Epoch [14/100], Step [80/140], Loss: 0.4714\n",
      "Epoch [14/100], Step [90/140], Loss: 0.3508\n",
      "Epoch [14/100], Step [100/140], Loss: 0.0036\n",
      "Epoch [14/100], Step [110/140], Loss: 0.0083\n",
      "Epoch [14/100], Step [120/140], Loss: 0.0341\n",
      "Epoch [14/100], Step [130/140], Loss: 0.0048\n",
      "Epoch [14/100], Step [140/140], Loss: 0.0128\n",
      "Epoch [15/100], Step [10/140], Loss: 0.0042\n",
      "Epoch [15/100], Step [20/140], Loss: 0.1288\n",
      "Epoch [15/100], Step [30/140], Loss: 0.0078\n",
      "Epoch [15/100], Step [40/140], Loss: 0.7502\n",
      "Epoch [15/100], Step [50/140], Loss: 0.0041\n",
      "Epoch [15/100], Step [60/140], Loss: 0.1672\n",
      "Epoch [15/100], Step [70/140], Loss: 0.6770\n",
      "Epoch [15/100], Step [80/140], Loss: 0.0190\n",
      "Epoch [15/100], Step [90/140], Loss: 0.0043\n",
      "Epoch [15/100], Step [100/140], Loss: 0.6507\n",
      "Epoch [15/100], Step [110/140], Loss: 0.7307\n",
      "Epoch [15/100], Step [120/140], Loss: 0.8280\n",
      "Epoch [15/100], Step [130/140], Loss: 0.4466\n",
      "Epoch [15/100], Step [140/140], Loss: 0.0135\n",
      "Epoch [16/100], Step [10/140], Loss: 0.2020\n",
      "Epoch [16/100], Step [20/140], Loss: 0.0051\n",
      "Epoch [16/100], Step [30/140], Loss: 0.7078\n",
      "Epoch [16/100], Step [40/140], Loss: 0.0044\n",
      "Epoch [16/100], Step [50/140], Loss: 0.0049\n",
      "Epoch [16/100], Step [60/140], Loss: 0.0104\n",
      "Epoch [16/100], Step [70/140], Loss: 0.3408\n",
      "Epoch [16/100], Step [80/140], Loss: 0.0107\n",
      "Epoch [16/100], Step [90/140], Loss: 0.6966\n",
      "Epoch [16/100], Step [100/140], Loss: 0.0052\n",
      "Epoch [16/100], Step [110/140], Loss: 0.6621\n",
      "Epoch [16/100], Step [120/140], Loss: 0.1239\n",
      "Epoch [16/100], Step [130/140], Loss: 0.5178\n",
      "Epoch [16/100], Step [140/140], Loss: 0.0238\n",
      "Epoch [17/100], Step [10/140], Loss: 0.0030\n",
      "Epoch [17/100], Step [20/140], Loss: 0.0055\n",
      "Epoch [17/100], Step [30/140], Loss: 0.1905\n",
      "Epoch [17/100], Step [40/140], Loss: 0.0122\n",
      "Epoch [17/100], Step [50/140], Loss: 0.0112\n",
      "Epoch [17/100], Step [60/140], Loss: 0.0035\n",
      "Epoch [17/100], Step [70/140], Loss: 0.1682\n",
      "Epoch [17/100], Step [80/140], Loss: 0.0036\n",
      "Epoch [17/100], Step [90/140], Loss: 0.0047\n",
      "Epoch [17/100], Step [100/140], Loss: 0.0032\n",
      "Epoch [17/100], Step [110/140], Loss: 0.4397\n",
      "Epoch [17/100], Step [120/140], Loss: 0.0064\n",
      "Epoch [17/100], Step [130/140], Loss: 0.0030\n",
      "Epoch [17/100], Step [140/140], Loss: 0.9139\n",
      "Epoch [18/100], Step [10/140], Loss: 0.0015\n",
      "Epoch [18/100], Step [20/140], Loss: 0.1820\n",
      "Epoch [18/100], Step [30/140], Loss: 0.0053\n",
      "Epoch [18/100], Step [40/140], Loss: 0.2472\n",
      "Epoch [18/100], Step [50/140], Loss: 0.4602\n",
      "Epoch [18/100], Step [60/140], Loss: 0.2591\n",
      "Epoch [18/100], Step [70/140], Loss: 0.0025\n",
      "Epoch [18/100], Step [80/140], Loss: 0.0133\n",
      "Epoch [18/100], Step [90/140], Loss: 0.7431\n",
      "Epoch [18/100], Step [100/140], Loss: 0.4216\n",
      "Epoch [18/100], Step [110/140], Loss: 0.0029\n",
      "Epoch [18/100], Step [120/140], Loss: 0.0022\n",
      "Epoch [18/100], Step [130/140], Loss: 0.0034\n",
      "Epoch [18/100], Step [140/140], Loss: 0.4488\n",
      "Epoch [19/100], Step [10/140], Loss: 0.1387\n",
      "Epoch [19/100], Step [20/140], Loss: 0.5611\n",
      "Epoch [19/100], Step [30/140], Loss: 0.4707\n",
      "Epoch [19/100], Step [40/140], Loss: 0.0048\n",
      "Epoch [19/100], Step [50/140], Loss: 0.5842\n",
      "Epoch [19/100], Step [60/140], Loss: 0.0032\n",
      "Epoch [19/100], Step [70/140], Loss: 0.4450\n",
      "Epoch [19/100], Step [80/140], Loss: 0.0082\n",
      "Epoch [19/100], Step [90/140], Loss: 0.7323\n",
      "Epoch [19/100], Step [100/140], Loss: 0.1602\n",
      "Epoch [19/100], Step [110/140], Loss: 0.5344\n",
      "Epoch [19/100], Step [120/140], Loss: 0.0036\n",
      "Epoch [19/100], Step [130/140], Loss: 0.4373\n",
      "Epoch [19/100], Step [140/140], Loss: 0.4137\n",
      "Epoch [20/100], Step [10/140], Loss: 0.4813\n",
      "Epoch [20/100], Step [20/140], Loss: 0.2616\n",
      "Epoch [20/100], Step [30/140], Loss: 0.2643\n",
      "Epoch [20/100], Step [40/140], Loss: 0.5604\n",
      "Epoch [20/100], Step [50/140], Loss: 0.0039\n",
      "Epoch [20/100], Step [60/140], Loss: 0.0250\n",
      "Epoch [20/100], Step [70/140], Loss: 0.2059\n",
      "Epoch [20/100], Step [80/140], Loss: 0.0026\n",
      "Epoch [20/100], Step [90/140], Loss: 0.2635\n",
      "Epoch [20/100], Step [100/140], Loss: 0.3906\n",
      "Epoch [20/100], Step [110/140], Loss: 0.2853\n",
      "Epoch [20/100], Step [120/140], Loss: 0.0077\n",
      "Epoch [20/100], Step [130/140], Loss: 0.4789\n",
      "Epoch [20/100], Step [140/140], Loss: 0.5759\n",
      "Epoch [21/100], Step [10/140], Loss: 0.4596\n",
      "Epoch [21/100], Step [20/140], Loss: 0.0036\n",
      "Epoch [21/100], Step [30/140], Loss: 0.5210\n",
      "Epoch [21/100], Step [40/140], Loss: 0.0050\n",
      "Epoch [21/100], Step [50/140], Loss: 0.1512\n",
      "Epoch [21/100], Step [60/140], Loss: 0.7221\n",
      "Epoch [21/100], Step [70/140], Loss: 0.3686\n",
      "Epoch [21/100], Step [80/140], Loss: 0.0023\n",
      "Epoch [21/100], Step [90/140], Loss: 0.0059\n",
      "Epoch [21/100], Step [100/140], Loss: 0.3478\n",
      "Epoch [21/100], Step [110/140], Loss: 0.1185\n",
      "Epoch [21/100], Step [120/140], Loss: 0.7232\n",
      "Epoch [21/100], Step [130/140], Loss: 0.0020\n",
      "Epoch [21/100], Step [140/140], Loss: 0.3342\n",
      "Epoch [22/100], Step [10/140], Loss: 0.3520\n",
      "Epoch [22/100], Step [20/140], Loss: 0.0528\n",
      "Epoch [22/100], Step [30/140], Loss: 0.6072\n",
      "Epoch [22/100], Step [40/140], Loss: 0.0038\n",
      "Epoch [22/100], Step [50/140], Loss: 0.0091\n",
      "Epoch [22/100], Step [60/140], Loss: 0.0028\n",
      "Epoch [22/100], Step [70/140], Loss: 0.4395\n",
      "Epoch [22/100], Step [80/140], Loss: 0.0049\n",
      "Epoch [22/100], Step [90/140], Loss: 0.8108\n",
      "Epoch [22/100], Step [100/140], Loss: 0.0054\n",
      "Epoch [22/100], Step [110/140], Loss: 0.5271\n",
      "Epoch [22/100], Step [120/140], Loss: 0.6677\n",
      "Epoch [22/100], Step [130/140], Loss: 0.3156\n",
      "Epoch [22/100], Step [140/140], Loss: 0.0032\n",
      "Epoch [23/100], Step [10/140], Loss: 0.0024\n",
      "Epoch [23/100], Step [20/140], Loss: 0.6759\n",
      "Epoch [23/100], Step [30/140], Loss: 0.3485\n",
      "Epoch [23/100], Step [40/140], Loss: 0.0009\n",
      "Epoch [23/100], Step [50/140], Loss: 0.0053\n",
      "Epoch [23/100], Step [60/140], Loss: 0.0081\n",
      "Epoch [23/100], Step [70/140], Loss: 0.5261\n",
      "Epoch [23/100], Step [80/140], Loss: 0.1126\n",
      "Epoch [23/100], Step [90/140], Loss: 0.4775\n",
      "Epoch [23/100], Step [100/140], Loss: 0.0071\n",
      "Epoch [23/100], Step [110/140], Loss: 0.0014\n",
      "Epoch [23/100], Step [120/140], Loss: 0.0058\n",
      "Epoch [23/100], Step [130/140], Loss: 0.5341\n",
      "Epoch [23/100], Step [140/140], Loss: 0.0016\n",
      "Epoch [24/100], Step [10/140], Loss: 0.5099\n",
      "Epoch [24/100], Step [20/140], Loss: 0.0019\n",
      "Epoch [24/100], Step [30/140], Loss: 0.5844\n",
      "Epoch [24/100], Step [40/140], Loss: 0.6935\n",
      "Epoch [24/100], Step [50/140], Loss: 0.2885\n",
      "Epoch [24/100], Step [60/140], Loss: 0.0061\n",
      "Epoch [24/100], Step [70/140], Loss: 0.6111\n",
      "Epoch [24/100], Step [80/140], Loss: 0.5966\n",
      "Epoch [24/100], Step [90/140], Loss: 0.4938\n",
      "Epoch [24/100], Step [100/140], Loss: 0.5516\n",
      "Epoch [24/100], Step [110/140], Loss: 0.0020\n",
      "Epoch [24/100], Step [120/140], Loss: 0.5348\n",
      "Epoch [24/100], Step [130/140], Loss: 0.0010\n",
      "Epoch [24/100], Step [140/140], Loss: 0.0043\n",
      "Epoch [25/100], Step [10/140], Loss: 0.2620\n",
      "Epoch [25/100], Step [20/140], Loss: 0.0028\n",
      "Epoch [25/100], Step [30/140], Loss: 0.0035\n",
      "Epoch [25/100], Step [40/140], Loss: 0.6400\n",
      "Epoch [25/100], Step [50/140], Loss: 0.0111\n",
      "Epoch [25/100], Step [60/140], Loss: 0.0033\n",
      "Epoch [25/100], Step [70/140], Loss: 0.0056\n",
      "Epoch [25/100], Step [80/140], Loss: 0.0016\n",
      "Epoch [25/100], Step [90/140], Loss: 0.6826\n",
      "Epoch [25/100], Step [100/140], Loss: 0.3453\n",
      "Epoch [25/100], Step [110/140], Loss: 0.3404\n",
      "Epoch [25/100], Step [120/140], Loss: 0.5404\n",
      "Epoch [25/100], Step [130/140], Loss: 0.5385\n",
      "Epoch [25/100], Step [140/140], Loss: 0.0035\n",
      "Epoch [26/100], Step [10/140], Loss: 0.1262\n",
      "Epoch [26/100], Step [20/140], Loss: 0.1897\n",
      "Epoch [26/100], Step [30/140], Loss: 0.0019\n",
      "Epoch [26/100], Step [40/140], Loss: 0.0054\n",
      "Epoch [26/100], Step [50/140], Loss: 0.0018\n",
      "Epoch [26/100], Step [60/140], Loss: 0.6692\n",
      "Epoch [26/100], Step [70/140], Loss: 0.4622\n",
      "Epoch [26/100], Step [80/140], Loss: 0.0034\n",
      "Epoch [26/100], Step [90/140], Loss: 0.0040\n",
      "Epoch [26/100], Step [100/140], Loss: 0.0007\n",
      "Epoch [26/100], Step [110/140], Loss: 0.3617\n",
      "Epoch [26/100], Step [120/140], Loss: 0.0027\n",
      "Epoch [26/100], Step [130/140], Loss: 0.0010\n",
      "Epoch [26/100], Step [140/140], Loss: 0.0016\n",
      "Epoch [27/100], Step [10/140], Loss: 0.0043\n",
      "Epoch [27/100], Step [20/140], Loss: 0.5122\n",
      "Epoch [27/100], Step [30/140], Loss: 0.0056\n",
      "Epoch [27/100], Step [40/140], Loss: 0.1327\n",
      "Epoch [27/100], Step [50/140], Loss: 0.2451\n",
      "Epoch [27/100], Step [60/140], Loss: 0.0896\n",
      "Epoch [27/100], Step [70/140], Loss: 0.0030\n",
      "Epoch [27/100], Step [80/140], Loss: 0.0042\n",
      "Epoch [27/100], Step [90/140], Loss: 0.0016\n",
      "Epoch [27/100], Step [100/140], Loss: 0.0059\n",
      "Epoch [27/100], Step [110/140], Loss: 0.0035\n",
      "Epoch [27/100], Step [120/140], Loss: 0.0022\n",
      "Epoch [27/100], Step [130/140], Loss: 0.6462\n",
      "Epoch [27/100], Step [140/140], Loss: 0.5141\n",
      "Epoch [28/100], Step [10/140], Loss: 0.1857\n",
      "Epoch [28/100], Step [20/140], Loss: 0.0032\n",
      "Epoch [28/100], Step [30/140], Loss: 0.3062\n",
      "Epoch [28/100], Step [40/140], Loss: 0.0015\n",
      "Epoch [28/100], Step [50/140], Loss: 0.0098\n",
      "Epoch [28/100], Step [60/140], Loss: 0.0030\n",
      "Epoch [28/100], Step [70/140], Loss: 0.3216\n",
      "Epoch [28/100], Step [80/140], Loss: 0.0011\n",
      "Epoch [28/100], Step [90/140], Loss: 0.3722\n",
      "Epoch [28/100], Step [100/140], Loss: 0.1967\n",
      "Epoch [28/100], Step [110/140], Loss: 0.1051\n",
      "Epoch [28/100], Step [120/140], Loss: 0.0188\n",
      "Epoch [28/100], Step [130/140], Loss: 0.7168\n",
      "Epoch [28/100], Step [140/140], Loss: 0.0051\n",
      "Epoch [29/100], Step [10/140], Loss: 0.0044\n",
      "Epoch [29/100], Step [20/140], Loss: 0.0021\n",
      "Epoch [29/100], Step [30/140], Loss: 0.0009\n",
      "Epoch [29/100], Step [40/140], Loss: 0.2539\n",
      "Epoch [29/100], Step [50/140], Loss: 0.5867\n",
      "Epoch [29/100], Step [60/140], Loss: 0.0054\n",
      "Epoch [29/100], Step [70/140], Loss: 0.5290\n",
      "Epoch [29/100], Step [80/140], Loss: 0.2098\n",
      "Epoch [29/100], Step [90/140], Loss: 0.0020\n",
      "Epoch [29/100], Step [100/140], Loss: 0.3947\n",
      "Epoch [29/100], Step [110/140], Loss: 0.7689\n",
      "Epoch [29/100], Step [120/140], Loss: 0.5418\n",
      "Epoch [29/100], Step [130/140], Loss: 0.0025\n",
      "Epoch [29/100], Step [140/140], Loss: 0.0019\n",
      "Epoch [30/100], Step [10/140], Loss: 0.2195\n",
      "Epoch [30/100], Step [20/140], Loss: 0.0012\n",
      "Epoch [30/100], Step [30/140], Loss: 0.0019\n",
      "Epoch [30/100], Step [40/140], Loss: 0.5244\n",
      "Epoch [30/100], Step [50/140], Loss: 0.0052\n",
      "Epoch [30/100], Step [60/140], Loss: 0.0005\n",
      "Epoch [30/100], Step [70/140], Loss: 0.0803\n",
      "Epoch [30/100], Step [80/140], Loss: 0.6591\n",
      "Epoch [30/100], Step [90/140], Loss: 0.4231\n",
      "Epoch [30/100], Step [100/140], Loss: 0.0014\n",
      "Epoch [30/100], Step [110/140], Loss: 0.0026\n",
      "Epoch [30/100], Step [120/140], Loss: 0.0010\n",
      "Epoch [30/100], Step [130/140], Loss: 0.4878\n",
      "Epoch [30/100], Step [140/140], Loss: 0.0041\n",
      "Epoch [31/100], Step [10/140], Loss: 0.3702\n",
      "Epoch [31/100], Step [20/140], Loss: 0.3081\n",
      "Epoch [31/100], Step [30/140], Loss: 0.0012\n",
      "Epoch [31/100], Step [40/140], Loss: 0.0025\n",
      "Epoch [31/100], Step [50/140], Loss: 0.0012\n",
      "Epoch [31/100], Step [60/140], Loss: 0.3560\n",
      "Epoch [31/100], Step [70/140], Loss: 0.6561\n",
      "Epoch [31/100], Step [80/140], Loss: 0.0020\n",
      "Epoch [31/100], Step [90/140], Loss: 0.3113\n",
      "Epoch [31/100], Step [100/140], Loss: 0.0025\n",
      "Epoch [31/100], Step [110/140], Loss: 0.0036\n",
      "Epoch [31/100], Step [120/140], Loss: 0.7030\n",
      "Epoch [31/100], Step [130/140], Loss: 0.0026\n",
      "Epoch [31/100], Step [140/140], Loss: 0.6748\n",
      "Epoch [32/100], Step [10/140], Loss: 0.4213\n",
      "Epoch [32/100], Step [20/140], Loss: 0.6250\n",
      "Epoch [32/100], Step [30/140], Loss: 0.0008\n",
      "Epoch [32/100], Step [40/140], Loss: 0.0015\n",
      "Epoch [32/100], Step [50/140], Loss: 0.0042\n",
      "Epoch [32/100], Step [60/140], Loss: 0.0008\n",
      "Epoch [32/100], Step [70/140], Loss: 0.2747\n",
      "Epoch [32/100], Step [80/140], Loss: 0.7318\n",
      "Epoch [32/100], Step [90/140], Loss: 0.1036\n",
      "Epoch [32/100], Step [100/140], Loss: 0.4190\n",
      "Epoch [32/100], Step [110/140], Loss: 0.3374\n",
      "Epoch [32/100], Step [120/140], Loss: 0.0035\n",
      "Epoch [32/100], Step [130/140], Loss: 0.0012\n",
      "Epoch [32/100], Step [140/140], Loss: 0.3764\n",
      "Epoch [33/100], Step [10/140], Loss: 0.0030\n",
      "Epoch [33/100], Step [20/140], Loss: 0.0988\n",
      "Epoch [33/100], Step [30/140], Loss: 0.0964\n",
      "Epoch [33/100], Step [40/140], Loss: 0.0029\n",
      "Epoch [33/100], Step [50/140], Loss: 0.5017\n",
      "Epoch [33/100], Step [60/140], Loss: 0.3836\n",
      "Epoch [33/100], Step [70/140], Loss: 0.3737\n",
      "Epoch [33/100], Step [80/140], Loss: 0.0006\n",
      "Epoch [33/100], Step [90/140], Loss: 0.0021\n",
      "Epoch [33/100], Step [100/140], Loss: 0.3327\n",
      "Epoch [33/100], Step [110/140], Loss: 0.6288\n",
      "Epoch [33/100], Step [120/140], Loss: 0.0012\n",
      "Epoch [33/100], Step [130/140], Loss: 0.0012\n",
      "Epoch [33/100], Step [140/140], Loss: 0.0009\n",
      "Epoch [34/100], Step [10/140], Loss: 0.0017\n",
      "Epoch [34/100], Step [20/140], Loss: 0.1613\n",
      "Epoch [34/100], Step [30/140], Loss: 0.1745\n",
      "Epoch [34/100], Step [40/140], Loss: 0.0048\n",
      "Epoch [34/100], Step [50/140], Loss: 0.0037\n",
      "Epoch [34/100], Step [60/140], Loss: 0.1083\n",
      "Epoch [34/100], Step [70/140], Loss: 0.0007\n",
      "Epoch [34/100], Step [80/140], Loss: 0.0037\n",
      "Epoch [34/100], Step [90/140], Loss: 0.0019\n",
      "Epoch [34/100], Step [100/140], Loss: 0.0055\n",
      "Epoch [34/100], Step [110/140], Loss: 0.0019\n",
      "Epoch [34/100], Step [120/140], Loss: 0.3476\n",
      "Epoch [34/100], Step [130/140], Loss: 0.0014\n",
      "Epoch [34/100], Step [140/140], Loss: 0.0029\n",
      "Epoch [35/100], Step [10/140], Loss: 0.2016\n",
      "Epoch [35/100], Step [20/140], Loss: 0.0018\n",
      "Epoch [35/100], Step [30/140], Loss: 0.0031\n",
      "Epoch [35/100], Step [40/140], Loss: 0.0022\n",
      "Epoch [35/100], Step [50/140], Loss: 0.7007\n",
      "Epoch [35/100], Step [60/140], Loss: 0.6733\n",
      "Epoch [35/100], Step [70/140], Loss: 0.4715\n",
      "Epoch [35/100], Step [80/140], Loss: 0.0075\n",
      "Epoch [35/100], Step [90/140], Loss: 0.0012\n",
      "Epoch [35/100], Step [100/140], Loss: 0.0020\n",
      "Epoch [35/100], Step [110/140], Loss: 0.0021\n",
      "Epoch [35/100], Step [120/140], Loss: 0.0151\n",
      "Epoch [35/100], Step [130/140], Loss: 0.0015\n",
      "Epoch [35/100], Step [140/140], Loss: 0.0010\n",
      "Epoch [36/100], Step [10/140], Loss: 0.0010\n",
      "Epoch [36/100], Step [20/140], Loss: 0.0018\n",
      "Epoch [36/100], Step [30/140], Loss: 0.4382\n",
      "Epoch [36/100], Step [40/140], Loss: 0.0020\n",
      "Epoch [36/100], Step [50/140], Loss: 0.0015\n",
      "Epoch [36/100], Step [60/140], Loss: 0.5933\n",
      "Epoch [36/100], Step [70/140], Loss: 0.0038\n",
      "Epoch [36/100], Step [80/140], Loss: 0.0017\n",
      "Epoch [36/100], Step [90/140], Loss: 0.0021\n",
      "Epoch [36/100], Step [100/140], Loss: 0.0045\n",
      "Epoch [36/100], Step [110/140], Loss: 0.0003\n",
      "Epoch [36/100], Step [120/140], Loss: 0.0009\n",
      "Epoch [36/100], Step [130/140], Loss: 0.0022\n",
      "Epoch [36/100], Step [140/140], Loss: 0.0021\n",
      "Epoch [37/100], Step [10/140], Loss: 0.0012\n",
      "Epoch [37/100], Step [20/140], Loss: 0.0014\n",
      "Epoch [37/100], Step [30/140], Loss: 0.0007\n",
      "Epoch [37/100], Step [40/140], Loss: 0.1075\n",
      "Epoch [37/100], Step [50/140], Loss: 0.0030\n",
      "Epoch [37/100], Step [60/140], Loss: 0.6346\n",
      "Epoch [37/100], Step [70/140], Loss: 0.4381\n",
      "Epoch [37/100], Step [80/140], Loss: 0.0008\n",
      "Epoch [37/100], Step [90/140], Loss: 0.4221\n",
      "Epoch [37/100], Step [100/140], Loss: 0.0013\n",
      "Epoch [37/100], Step [110/140], Loss: 0.4545\n",
      "Epoch [37/100], Step [120/140], Loss: 0.5508\n",
      "Epoch [37/100], Step [130/140], Loss: 0.3847\n",
      "Epoch [37/100], Step [140/140], Loss: 0.7624\n",
      "Epoch [38/100], Step [10/140], Loss: 0.0010\n",
      "Epoch [38/100], Step [20/140], Loss: 0.4716\n",
      "Epoch [38/100], Step [30/140], Loss: 0.1349\n",
      "Epoch [38/100], Step [40/140], Loss: 0.2000\n",
      "Epoch [38/100], Step [50/140], Loss: 0.0014\n",
      "Epoch [38/100], Step [60/140], Loss: 0.7217\n",
      "Epoch [38/100], Step [70/140], Loss: 0.0019\n",
      "Epoch [38/100], Step [80/140], Loss: 0.3738\n",
      "Epoch [38/100], Step [90/140], Loss: 0.0930\n",
      "Epoch [38/100], Step [100/140], Loss: 0.6797\n",
      "Epoch [38/100], Step [110/140], Loss: 0.0021\n",
      "Epoch [38/100], Step [120/140], Loss: 0.1966\n",
      "Epoch [38/100], Step [130/140], Loss: 0.0016\n",
      "Epoch [38/100], Step [140/140], Loss: 0.3023\n",
      "Epoch [39/100], Step [10/140], Loss: 0.5020\n",
      "Epoch [39/100], Step [20/140], Loss: 0.2998\n",
      "Epoch [39/100], Step [30/140], Loss: 0.6135\n",
      "Epoch [39/100], Step [40/140], Loss: 0.3952\n",
      "Epoch [39/100], Step [50/140], Loss: 0.0021\n",
      "Epoch [39/100], Step [60/140], Loss: 0.0013\n",
      "Epoch [39/100], Step [70/140], Loss: 0.0015\n",
      "Epoch [39/100], Step [80/140], Loss: 0.0011\n",
      "Epoch [39/100], Step [90/140], Loss: 0.0007\n",
      "Epoch [39/100], Step [100/140], Loss: 0.6614\n",
      "Epoch [39/100], Step [110/140], Loss: 0.2909\n",
      "Epoch [39/100], Step [120/140], Loss: 0.0026\n",
      "Epoch [39/100], Step [130/140], Loss: 0.0008\n",
      "Epoch [39/100], Step [140/140], Loss: 0.0013\n",
      "Epoch [40/100], Step [10/140], Loss: 0.0005\n",
      "Epoch [40/100], Step [20/140], Loss: 0.0009\n",
      "Epoch [40/100], Step [30/140], Loss: 0.0008\n",
      "Epoch [40/100], Step [40/140], Loss: 0.1975\n",
      "Epoch [40/100], Step [50/140], Loss: 0.0004\n",
      "Epoch [40/100], Step [60/140], Loss: 0.0034\n",
      "Epoch [40/100], Step [70/140], Loss: 0.0032\n",
      "Epoch [40/100], Step [80/140], Loss: 0.3900\n",
      "Epoch [40/100], Step [90/140], Loss: 0.0013\n",
      "Epoch [40/100], Step [100/140], Loss: 0.7258\n",
      "Epoch [40/100], Step [110/140], Loss: 0.4697\n",
      "Epoch [40/100], Step [120/140], Loss: 0.0030\n",
      "Epoch [40/100], Step [130/140], Loss: 0.1510\n",
      "Epoch [40/100], Step [140/140], Loss: 0.6804\n",
      "Epoch [41/100], Step [10/140], Loss: 0.0010\n",
      "Epoch [41/100], Step [20/140], Loss: 0.6457\n",
      "Epoch [41/100], Step [30/140], Loss: 0.4798\n",
      "Epoch [41/100], Step [40/140], Loss: 0.0009\n",
      "Epoch [41/100], Step [50/140], Loss: 0.0795\n",
      "Epoch [41/100], Step [60/140], Loss: 0.2513\n",
      "Epoch [41/100], Step [70/140], Loss: 0.0042\n",
      "Epoch [41/100], Step [80/140], Loss: 0.0013\n",
      "Epoch [41/100], Step [90/140], Loss: 0.0006\n",
      "Epoch [41/100], Step [100/140], Loss: 0.4376\n",
      "Epoch [41/100], Step [110/140], Loss: 0.3366\n",
      "Epoch [41/100], Step [120/140], Loss: 0.3260\n",
      "Epoch [41/100], Step [130/140], Loss: 0.0012\n",
      "Epoch [41/100], Step [140/140], Loss: 0.0010\n",
      "Epoch [42/100], Step [10/140], Loss: 0.0013\n",
      "Epoch [42/100], Step [20/140], Loss: 0.4056\n",
      "Epoch [42/100], Step [30/140], Loss: 0.0014\n",
      "Epoch [42/100], Step [40/140], Loss: 0.0018\n",
      "Epoch [42/100], Step [50/140], Loss: 0.6162\n",
      "Epoch [42/100], Step [60/140], Loss: 0.0006\n",
      "Epoch [42/100], Step [70/140], Loss: 0.6944\n",
      "Epoch [42/100], Step [80/140], Loss: 0.2823\n",
      "Epoch [42/100], Step [90/140], Loss: 0.0021\n",
      "Epoch [42/100], Step [100/140], Loss: 0.0020\n",
      "Epoch [42/100], Step [110/140], Loss: 0.0074\n",
      "Epoch [42/100], Step [120/140], Loss: 0.0004\n",
      "Epoch [42/100], Step [130/140], Loss: 0.0008\n",
      "Epoch [42/100], Step [140/140], Loss: 0.5033\n",
      "Epoch [43/100], Step [10/140], Loss: 0.0011\n",
      "Epoch [43/100], Step [20/140], Loss: 0.0016\n",
      "Epoch [43/100], Step [30/140], Loss: 0.1034\n",
      "Epoch [43/100], Step [40/140], Loss: 0.0009\n",
      "Epoch [43/100], Step [50/140], Loss: 0.0015\n",
      "Epoch [43/100], Step [60/140], Loss: 0.0008\n",
      "Epoch [43/100], Step [70/140], Loss: 0.2522\n",
      "Epoch [43/100], Step [80/140], Loss: 0.3697\n",
      "Epoch [43/100], Step [90/140], Loss: 0.0004\n",
      "Epoch [43/100], Step [100/140], Loss: 0.0006\n",
      "Epoch [43/100], Step [110/140], Loss: 0.0013\n",
      "Epoch [43/100], Step [120/140], Loss: 0.7659\n",
      "Epoch [43/100], Step [130/140], Loss: 0.0008\n",
      "Epoch [43/100], Step [140/140], Loss: 0.4013\n",
      "Epoch [44/100], Step [10/140], Loss: 0.4582\n",
      "Epoch [44/100], Step [20/140], Loss: 0.0007\n",
      "Epoch [44/100], Step [30/140], Loss: 0.2199\n",
      "Epoch [44/100], Step [40/140], Loss: 0.0903\n",
      "Epoch [44/100], Step [50/140], Loss: 0.0004\n",
      "Epoch [44/100], Step [60/140], Loss: 0.0017\n",
      "Epoch [44/100], Step [70/140], Loss: 0.0008\n",
      "Epoch [44/100], Step [80/140], Loss: 0.1247\n",
      "Epoch [44/100], Step [90/140], Loss: 0.0011\n",
      "Epoch [44/100], Step [100/140], Loss: 0.0014\n",
      "Epoch [44/100], Step [110/140], Loss: 0.0010\n",
      "Epoch [44/100], Step [120/140], Loss: 0.1471\n",
      "Epoch [44/100], Step [130/140], Loss: 0.0009\n",
      "Epoch [44/100], Step [140/140], Loss: 0.0059\n",
      "Epoch [45/100], Step [10/140], Loss: 0.1701\n",
      "Epoch [45/100], Step [20/140], Loss: 0.0009\n",
      "Epoch [45/100], Step [30/140], Loss: 0.0006\n",
      "Epoch [45/100], Step [40/140], Loss: 0.0048\n",
      "Epoch [45/100], Step [50/140], Loss: 0.5251\n",
      "Epoch [45/100], Step [60/140], Loss: 0.0006\n",
      "Epoch [45/100], Step [70/140], Loss: 0.4231\n",
      "Epoch [45/100], Step [80/140], Loss: 0.0019\n",
      "Epoch [45/100], Step [90/140], Loss: 0.0033\n",
      "Epoch [45/100], Step [100/140], Loss: 0.0006\n",
      "Epoch [45/100], Step [110/140], Loss: 0.5193\n",
      "Epoch [45/100], Step [120/140], Loss: 0.2045\n",
      "Epoch [45/100], Step [130/140], Loss: 0.0010\n",
      "Epoch [45/100], Step [140/140], Loss: 0.5435\n",
      "Epoch [46/100], Step [10/140], Loss: 0.1076\n",
      "Epoch [46/100], Step [20/140], Loss: 0.0013\n",
      "Epoch [46/100], Step [30/140], Loss: 0.1574\n",
      "Epoch [46/100], Step [40/140], Loss: 0.0019\n",
      "Epoch [46/100], Step [50/140], Loss: 0.3177\n",
      "Epoch [46/100], Step [60/140], Loss: 0.3602\n",
      "Epoch [46/100], Step [70/140], Loss: 0.0008\n",
      "Epoch [46/100], Step [80/140], Loss: 0.1608\n",
      "Epoch [46/100], Step [90/140], Loss: 0.4203\n",
      "Epoch [46/100], Step [100/140], Loss: 0.0006\n",
      "Epoch [46/100], Step [110/140], Loss: 0.7082\n",
      "Epoch [46/100], Step [120/140], Loss: 0.0014\n",
      "Epoch [46/100], Step [130/140], Loss: 0.4338\n",
      "Epoch [46/100], Step [140/140], Loss: 0.0005\n",
      "Epoch [47/100], Step [10/140], Loss: 0.0013\n",
      "Epoch [47/100], Step [20/140], Loss: 0.0026\n",
      "Epoch [47/100], Step [30/140], Loss: 0.0096\n",
      "Epoch [47/100], Step [40/140], Loss: 0.0011\n",
      "Epoch [47/100], Step [50/140], Loss: 0.1084\n",
      "Epoch [47/100], Step [60/140], Loss: 0.0012\n",
      "Epoch [47/100], Step [70/140], Loss: 0.1969\n",
      "Epoch [47/100], Step [80/140], Loss: 0.5523\n",
      "Epoch [47/100], Step [90/140], Loss: 0.0005\n",
      "Epoch [47/100], Step [100/140], Loss: 0.0007\n",
      "Epoch [47/100], Step [110/140], Loss: 0.0012\n",
      "Epoch [47/100], Step [120/140], Loss: 0.6732\n",
      "Epoch [47/100], Step [130/140], Loss: 0.2770\n",
      "Epoch [47/100], Step [140/140], Loss: 0.0015\n",
      "Epoch [48/100], Step [10/140], Loss: 0.1801\n",
      "Epoch [48/100], Step [20/140], Loss: 0.0007\n",
      "Epoch [48/100], Step [30/140], Loss: 0.6695\n",
      "Epoch [48/100], Step [40/140], Loss: 0.0011\n",
      "Epoch [48/100], Step [50/140], Loss: 0.7318\n",
      "Epoch [48/100], Step [60/140], Loss: 0.4460\n",
      "Epoch [48/100], Step [70/140], Loss: 0.0031\n",
      "Epoch [48/100], Step [80/140], Loss: 0.3709\n",
      "Epoch [48/100], Step [90/140], Loss: 0.0006\n",
      "Epoch [48/100], Step [100/140], Loss: 0.3871\n",
      "Epoch [48/100], Step [110/140], Loss: 0.0007\n",
      "Epoch [48/100], Step [120/140], Loss: 0.6847\n",
      "Epoch [48/100], Step [130/140], Loss: 0.0040\n",
      "Epoch [48/100], Step [140/140], Loss: 0.0011\n",
      "Epoch [49/100], Step [10/140], Loss: 0.1029\n",
      "Epoch [49/100], Step [20/140], Loss: 0.0016\n",
      "Epoch [49/100], Step [30/140], Loss: 0.5864\n",
      "Epoch [49/100], Step [40/140], Loss: 0.0008\n",
      "Epoch [49/100], Step [50/140], Loss: 0.0021\n",
      "Epoch [49/100], Step [60/140], Loss: 0.6568\n",
      "Epoch [49/100], Step [70/140], Loss: 0.0006\n",
      "Epoch [49/100], Step [80/140], Loss: 0.0011\n",
      "Epoch [49/100], Step [90/140], Loss: 0.0009\n",
      "Epoch [49/100], Step [100/140], Loss: 0.0031\n",
      "Epoch [49/100], Step [110/140], Loss: 0.0011\n",
      "Epoch [49/100], Step [120/140], Loss: 0.7268\n",
      "Epoch [49/100], Step [130/140], Loss: 0.0011\n",
      "Epoch [49/100], Step [140/140], Loss: 0.0006\n",
      "Epoch [50/100], Step [10/140], Loss: 0.0590\n",
      "Epoch [50/100], Step [20/140], Loss: 0.1626\n",
      "Epoch [50/100], Step [30/140], Loss: 0.0008\n",
      "Epoch [50/100], Step [40/140], Loss: 0.3960\n",
      "Epoch [50/100], Step [50/140], Loss: 0.0007\n",
      "Epoch [50/100], Step [60/140], Loss: 0.0012\n",
      "Epoch [50/100], Step [70/140], Loss: 0.3029\n",
      "Epoch [50/100], Step [80/140], Loss: 0.0016\n",
      "Epoch [50/100], Step [90/140], Loss: 0.0005\n",
      "Epoch [50/100], Step [100/140], Loss: 0.3869\n",
      "Epoch [50/100], Step [110/140], Loss: 0.5179\n",
      "Epoch [50/100], Step [120/140], Loss: 0.0005\n",
      "Epoch [50/100], Step [130/140], Loss: 0.7471\n",
      "Epoch [50/100], Step [140/140], Loss: 0.0013\n",
      "Epoch [51/100], Step [10/140], Loss: 0.0015\n",
      "Epoch [51/100], Step [20/140], Loss: 0.0014\n",
      "Epoch [51/100], Step [30/140], Loss: 0.0007\n",
      "Epoch [51/100], Step [40/140], Loss: 0.0005\n",
      "Epoch [51/100], Step [50/140], Loss: 0.0017\n",
      "Epoch [51/100], Step [60/140], Loss: 0.0016\n",
      "Epoch [51/100], Step [70/140], Loss: 0.0004\n",
      "Epoch [51/100], Step [80/140], Loss: 0.2755\n",
      "Epoch [51/100], Step [90/140], Loss: 0.4153\n",
      "Epoch [51/100], Step [100/140], Loss: 0.4685\n",
      "Epoch [51/100], Step [110/140], Loss: 0.1930\n",
      "Epoch [51/100], Step [120/140], Loss: 0.7207\n",
      "Epoch [51/100], Step [130/140], Loss: 0.4706\n",
      "Epoch [51/100], Step [140/140], Loss: 0.0010\n",
      "Epoch [52/100], Step [10/140], Loss: 0.1090\n",
      "Epoch [52/100], Step [20/140], Loss: 0.1218\n",
      "Epoch [52/100], Step [30/140], Loss: 0.2403\n",
      "Epoch [52/100], Step [40/140], Loss: 0.1931\n",
      "Epoch [52/100], Step [50/140], Loss: 0.0004\n",
      "Epoch [52/100], Step [60/140], Loss: 0.0009\n",
      "Epoch [52/100], Step [70/140], Loss: 0.1807\n",
      "Epoch [52/100], Step [80/140], Loss: 0.4613\n",
      "Epoch [52/100], Step [90/140], Loss: 0.0008\n",
      "Epoch [52/100], Step [100/140], Loss: 0.0007\n",
      "Epoch [52/100], Step [110/140], Loss: 0.0017\n",
      "Epoch [52/100], Step [120/140], Loss: 0.4095\n",
      "Epoch [52/100], Step [130/140], Loss: 0.0005\n",
      "Epoch [52/100], Step [140/140], Loss: 0.4736\n",
      "Epoch [53/100], Step [10/140], Loss: 0.4242\n",
      "Epoch [53/100], Step [20/140], Loss: 0.3819\n",
      "Epoch [53/100], Step [30/140], Loss: 0.0009\n",
      "Epoch [53/100], Step [40/140], Loss: 0.0005\n",
      "Epoch [53/100], Step [50/140], Loss: 0.1271\n",
      "Epoch [53/100], Step [60/140], Loss: 0.0006\n",
      "Epoch [53/100], Step [70/140], Loss: 0.3862\n",
      "Epoch [53/100], Step [80/140], Loss: 0.0005\n",
      "Epoch [53/100], Step [90/140], Loss: 0.0016\n",
      "Epoch [53/100], Step [100/140], Loss: 0.6811\n",
      "Epoch [53/100], Step [110/140], Loss: 0.2643\n",
      "Epoch [53/100], Step [120/140], Loss: 0.0002\n",
      "Epoch [53/100], Step [130/140], Loss: 0.4620\n",
      "Epoch [53/100], Step [140/140], Loss: 0.0010\n",
      "Epoch [54/100], Step [10/140], Loss: 0.0010\n",
      "Epoch [54/100], Step [20/140], Loss: 0.0007\n",
      "Epoch [54/100], Step [30/140], Loss: 0.0005\n",
      "Epoch [54/100], Step [40/140], Loss: 0.0005\n",
      "Epoch [54/100], Step [50/140], Loss: 0.6818\n",
      "Epoch [54/100], Step [60/140], Loss: 0.0031\n",
      "Epoch [54/100], Step [70/140], Loss: 0.0002\n",
      "Epoch [54/100], Step [80/140], Loss: 0.0009\n",
      "Epoch [54/100], Step [90/140], Loss: 0.0002\n",
      "Epoch [54/100], Step [100/140], Loss: 0.0011\n",
      "Epoch [54/100], Step [110/140], Loss: 0.0014\n",
      "Epoch [54/100], Step [120/140], Loss: 0.2610\n",
      "Epoch [54/100], Step [130/140], Loss: 0.0947\n",
      "Epoch [54/100], Step [140/140], Loss: 0.0002\n",
      "Epoch [55/100], Step [10/140], Loss: 0.3167\n",
      "Epoch [55/100], Step [20/140], Loss: 0.2816\n",
      "Epoch [55/100], Step [30/140], Loss: 0.0010\n",
      "Epoch [55/100], Step [40/140], Loss: 0.1979\n",
      "Epoch [55/100], Step [50/140], Loss: 0.0003\n",
      "Epoch [55/100], Step [60/140], Loss: 0.4652\n",
      "Epoch [55/100], Step [70/140], Loss: 0.1598\n",
      "Epoch [55/100], Step [80/140], Loss: 0.0004\n",
      "Epoch [55/100], Step [90/140], Loss: 0.5484\n",
      "Epoch [55/100], Step [100/140], Loss: 0.3732\n",
      "Epoch [55/100], Step [110/140], Loss: 0.1384\n",
      "Epoch [55/100], Step [120/140], Loss: 0.0017\n",
      "Epoch [55/100], Step [130/140], Loss: 0.1147\n",
      "Epoch [55/100], Step [140/140], Loss: 0.7433\n",
      "Epoch [56/100], Step [10/140], Loss: 0.0006\n",
      "Epoch [56/100], Step [20/140], Loss: 0.3708\n",
      "Epoch [56/100], Step [30/140], Loss: 0.6712\n",
      "Epoch [56/100], Step [40/140], Loss: 0.0004\n",
      "Epoch [56/100], Step [50/140], Loss: 0.4662\n",
      "Epoch [56/100], Step [60/140], Loss: 0.0004\n",
      "Epoch [56/100], Step [70/140], Loss: 0.3873\n",
      "Epoch [56/100], Step [80/140], Loss: 0.0016\n",
      "Epoch [56/100], Step [90/140], Loss: 0.0007\n",
      "Epoch [56/100], Step [100/140], Loss: 0.6962\n",
      "Epoch [56/100], Step [110/140], Loss: 0.0042\n",
      "Epoch [56/100], Step [120/140], Loss: 0.0014\n",
      "Epoch [56/100], Step [130/140], Loss: 0.0004\n",
      "Epoch [56/100], Step [140/140], Loss: 0.3855\n",
      "Epoch [57/100], Step [10/140], Loss: 0.5219\n",
      "Epoch [57/100], Step [20/140], Loss: 0.0014\n",
      "Epoch [57/100], Step [30/140], Loss: 0.2640\n",
      "Epoch [57/100], Step [40/140], Loss: 0.0008\n",
      "Epoch [57/100], Step [50/140], Loss: 0.0004\n",
      "Epoch [57/100], Step [60/140], Loss: 0.7460\n",
      "Epoch [57/100], Step [70/140], Loss: 0.0011\n",
      "Epoch [57/100], Step [80/140], Loss: 0.6555\n",
      "Epoch [57/100], Step [90/140], Loss: 0.0015\n",
      "Epoch [57/100], Step [100/140], Loss: 0.1305\n",
      "Epoch [57/100], Step [110/140], Loss: 0.2732\n",
      "Epoch [57/100], Step [120/140], Loss: 0.0007\n",
      "Epoch [57/100], Step [130/140], Loss: 0.0002\n",
      "Epoch [57/100], Step [140/140], Loss: 0.6089\n",
      "Epoch [58/100], Step [10/140], Loss: 0.3726\n",
      "Epoch [58/100], Step [20/140], Loss: 0.0009\n",
      "Epoch [58/100], Step [30/140], Loss: 0.5175\n",
      "Epoch [58/100], Step [40/140], Loss: 0.5181\n",
      "Epoch [58/100], Step [50/140], Loss: 0.1579\n",
      "Epoch [58/100], Step [60/140], Loss: 0.0005\n",
      "Epoch [58/100], Step [70/140], Loss: 0.0005\n",
      "Epoch [58/100], Step [80/140], Loss: 0.4037\n",
      "Epoch [58/100], Step [90/140], Loss: 0.0016\n",
      "Epoch [58/100], Step [100/140], Loss: 0.0003\n",
      "Epoch [58/100], Step [110/140], Loss: 0.3968\n",
      "Epoch [58/100], Step [120/140], Loss: 0.3687\n",
      "Epoch [58/100], Step [130/140], Loss: 0.0010\n",
      "Epoch [58/100], Step [140/140], Loss: 0.4139\n",
      "Epoch [59/100], Step [10/140], Loss: 0.0003\n",
      "Epoch [59/100], Step [20/140], Loss: 0.0008\n",
      "Epoch [59/100], Step [30/140], Loss: 0.0011\n",
      "Epoch [59/100], Step [40/140], Loss: 0.0006\n",
      "Epoch [59/100], Step [50/140], Loss: 0.0004\n",
      "Epoch [59/100], Step [60/140], Loss: 0.5668\n",
      "Epoch [59/100], Step [70/140], Loss: 0.6999\n",
      "Epoch [59/100], Step [80/140], Loss: 0.0019\n",
      "Epoch [59/100], Step [90/140], Loss: 0.5345\n",
      "Epoch [59/100], Step [100/140], Loss: 0.0006\n",
      "Epoch [59/100], Step [110/140], Loss: 0.0014\n",
      "Epoch [59/100], Step [120/140], Loss: 0.2817\n",
      "Epoch [59/100], Step [130/140], Loss: 0.0007\n",
      "Epoch [59/100], Step [140/140], Loss: 0.0003\n",
      "Epoch [60/100], Step [10/140], Loss: 0.2501\n",
      "Epoch [60/100], Step [20/140], Loss: 0.0005\n",
      "Epoch [60/100], Step [30/140], Loss: 0.0004\n",
      "Epoch [60/100], Step [40/140], Loss: 0.5864\n",
      "Epoch [60/100], Step [50/140], Loss: 0.0016\n",
      "Epoch [60/100], Step [60/140], Loss: 0.0009\n",
      "Epoch [60/100], Step [70/140], Loss: 0.0008\n",
      "Epoch [60/100], Step [80/140], Loss: 0.2557\n",
      "Epoch [60/100], Step [90/140], Loss: 0.1793\n",
      "Epoch [60/100], Step [100/140], Loss: 0.0010\n",
      "Epoch [60/100], Step [110/140], Loss: 0.2764\n",
      "Epoch [60/100], Step [120/140], Loss: 0.2834\n",
      "Epoch [60/100], Step [130/140], Loss: 0.0006\n",
      "Epoch [60/100], Step [140/140], Loss: 0.0001\n",
      "Epoch [61/100], Step [10/140], Loss: 0.0010\n",
      "Epoch [61/100], Step [20/140], Loss: 0.2601\n",
      "Epoch [61/100], Step [30/140], Loss: 0.0016\n",
      "Epoch [61/100], Step [40/140], Loss: 0.5017\n",
      "Epoch [61/100], Step [50/140], Loss: 0.0011\n",
      "Epoch [61/100], Step [60/140], Loss: 0.0004\n",
      "Epoch [61/100], Step [70/140], Loss: 0.6016\n",
      "Epoch [61/100], Step [80/140], Loss: 0.0002\n",
      "Epoch [61/100], Step [90/140], Loss: 0.0014\n",
      "Epoch [61/100], Step [100/140], Loss: 0.0006\n",
      "Epoch [61/100], Step [110/140], Loss: 0.4535\n",
      "Epoch [61/100], Step [120/140], Loss: 0.0008\n",
      "Epoch [61/100], Step [130/140], Loss: 0.3061\n",
      "Epoch [61/100], Step [140/140], Loss: 0.4232\n",
      "Epoch [62/100], Step [10/140], Loss: 0.0010\n",
      "Epoch [62/100], Step [20/140], Loss: 0.4536\n",
      "Epoch [62/100], Step [30/140], Loss: 0.1652\n",
      "Epoch [62/100], Step [40/140], Loss: 0.0005\n",
      "Epoch [62/100], Step [50/140], Loss: 0.0003\n",
      "Epoch [62/100], Step [60/140], Loss: 0.0056\n",
      "Epoch [62/100], Step [70/140], Loss: 0.7093\n",
      "Epoch [62/100], Step [80/140], Loss: 0.3306\n",
      "Epoch [62/100], Step [90/140], Loss: 0.7288\n",
      "Epoch [62/100], Step [100/140], Loss: 0.0001\n",
      "Epoch [62/100], Step [110/140], Loss: 0.0003\n",
      "Epoch [62/100], Step [120/140], Loss: 0.3214\n",
      "Epoch [62/100], Step [130/140], Loss: 0.0003\n",
      "Epoch [62/100], Step [140/140], Loss: 0.4084\n",
      "Epoch [63/100], Step [10/140], Loss: 0.0033\n",
      "Epoch [63/100], Step [20/140], Loss: 0.0010\n",
      "Epoch [63/100], Step [30/140], Loss: 0.0003\n",
      "Epoch [63/100], Step [40/140], Loss: 0.0010\n",
      "Epoch [63/100], Step [50/140], Loss: 0.1303\n",
      "Epoch [63/100], Step [60/140], Loss: 0.2975\n",
      "Epoch [63/100], Step [70/140], Loss: 0.6650\n",
      "Epoch [63/100], Step [80/140], Loss: 0.0020\n",
      "Epoch [63/100], Step [90/140], Loss: 0.4452\n",
      "Epoch [63/100], Step [100/140], Loss: 0.0008\n",
      "Epoch [63/100], Step [110/140], Loss: 0.1495\n",
      "Epoch [63/100], Step [120/140], Loss: 0.0006\n",
      "Epoch [63/100], Step [130/140], Loss: 0.0009\n",
      "Epoch [63/100], Step [140/140], Loss: 0.0007\n",
      "Epoch [64/100], Step [10/140], Loss: 0.0001\n",
      "Epoch [64/100], Step [20/140], Loss: 0.0008\n",
      "Epoch [64/100], Step [30/140], Loss: 0.5225\n",
      "Epoch [64/100], Step [40/140], Loss: 0.0010\n",
      "Epoch [64/100], Step [50/140], Loss: 0.0012\n",
      "Epoch [64/100], Step [60/140], Loss: 0.6566\n",
      "Epoch [64/100], Step [70/140], Loss: 0.0005\n",
      "Epoch [64/100], Step [80/140], Loss: 0.3852\n",
      "Epoch [64/100], Step [90/140], Loss: 0.7492\n",
      "Epoch [64/100], Step [100/140], Loss: 0.1040\n",
      "Epoch [64/100], Step [110/140], Loss: 0.3746\n",
      "Epoch [64/100], Step [120/140], Loss: 0.0013\n",
      "Epoch [64/100], Step [130/140], Loss: 0.0002\n",
      "Epoch [64/100], Step [140/140], Loss: 0.0003\n",
      "Epoch [65/100], Step [10/140], Loss: 0.0004\n",
      "Epoch [65/100], Step [20/140], Loss: 0.0029\n",
      "Epoch [65/100], Step [30/140], Loss: 0.0003\n",
      "Epoch [65/100], Step [40/140], Loss: 0.6563\n",
      "Epoch [65/100], Step [50/140], Loss: 0.0009\n",
      "Epoch [65/100], Step [60/140], Loss: 0.0009\n",
      "Epoch [65/100], Step [70/140], Loss: 0.6933\n",
      "Epoch [65/100], Step [80/140], Loss: 0.8726\n",
      "Epoch [65/100], Step [90/140], Loss: 0.1092\n",
      "Epoch [65/100], Step [100/140], Loss: 0.4254\n",
      "Epoch [65/100], Step [110/140], Loss: 0.3764\n",
      "Epoch [65/100], Step [120/140], Loss: 0.3130\n",
      "Epoch [65/100], Step [130/140], Loss: 0.4635\n",
      "Epoch [65/100], Step [140/140], Loss: 0.1682\n",
      "Epoch [66/100], Step [10/140], Loss: 0.4300\n",
      "Epoch [66/100], Step [20/140], Loss: 0.1746\n",
      "Epoch [66/100], Step [30/140], Loss: 0.2176\n",
      "Epoch [66/100], Step [40/140], Loss: 0.7063\n",
      "Epoch [66/100], Step [50/140], Loss: 0.0004\n",
      "Epoch [66/100], Step [60/140], Loss: 0.0006\n",
      "Epoch [66/100], Step [70/140], Loss: 0.0003\n",
      "Epoch [66/100], Step [80/140], Loss: 0.0014\n",
      "Epoch [66/100], Step [90/140], Loss: 0.0011\n",
      "Epoch [66/100], Step [100/140], Loss: 0.0038\n",
      "Epoch [66/100], Step [110/140], Loss: 0.0010\n",
      "Epoch [66/100], Step [120/140], Loss: 0.0003\n",
      "Epoch [66/100], Step [130/140], Loss: 0.0002\n",
      "Epoch [66/100], Step [140/140], Loss: 0.5678\n",
      "Epoch [67/100], Step [10/140], Loss: 0.2021\n",
      "Epoch [67/100], Step [20/140], Loss: 0.0003\n",
      "Epoch [67/100], Step [30/140], Loss: 0.1067\n",
      "Epoch [67/100], Step [40/140], Loss: 0.1107\n",
      "Epoch [67/100], Step [50/140], Loss: 0.0005\n",
      "Epoch [67/100], Step [60/140], Loss: 0.0005\n",
      "Epoch [67/100], Step [70/140], Loss: 0.0007\n",
      "Epoch [67/100], Step [80/140], Loss: 0.0008\n",
      "Epoch [67/100], Step [90/140], Loss: 0.0009\n",
      "Epoch [67/100], Step [100/140], Loss: 0.6645\n",
      "Epoch [67/100], Step [110/140], Loss: 0.0006\n",
      "Epoch [67/100], Step [120/140], Loss: 0.0002\n",
      "Epoch [67/100], Step [130/140], Loss: 0.6539\n",
      "Epoch [67/100], Step [140/140], Loss: 0.2562\n",
      "Epoch [68/100], Step [10/140], Loss: 0.0011\n",
      "Epoch [68/100], Step [20/140], Loss: 0.0003\n",
      "Epoch [68/100], Step [30/140], Loss: 0.2134\n",
      "Epoch [68/100], Step [40/140], Loss: 0.2468\n",
      "Epoch [68/100], Step [50/140], Loss: 0.0010\n",
      "Epoch [68/100], Step [60/140], Loss: 0.3831\n",
      "Epoch [68/100], Step [70/140], Loss: 0.5414\n",
      "Epoch [68/100], Step [80/140], Loss: 0.5182\n",
      "Epoch [68/100], Step [90/140], Loss: 0.0003\n",
      "Epoch [68/100], Step [100/140], Loss: 0.0006\n",
      "Epoch [68/100], Step [110/140], Loss: 0.0004\n",
      "Epoch [68/100], Step [120/140], Loss: 0.1221\n",
      "Epoch [68/100], Step [130/140], Loss: 0.0010\n",
      "Epoch [68/100], Step [140/140], Loss: 0.0007\n",
      "Epoch [69/100], Step [10/140], Loss: 0.0008\n",
      "Epoch [69/100], Step [20/140], Loss: 0.1071\n",
      "Epoch [69/100], Step [30/140], Loss: 0.0003\n",
      "Epoch [69/100], Step [40/140], Loss: 0.0002\n",
      "Epoch [69/100], Step [50/140], Loss: 0.1899\n",
      "Epoch [69/100], Step [60/140], Loss: 0.0010\n",
      "Epoch [69/100], Step [70/140], Loss: 0.6788\n",
      "Epoch [69/100], Step [80/140], Loss: 0.4255\n",
      "Epoch [69/100], Step [90/140], Loss: 0.4697\n",
      "Epoch [69/100], Step [100/140], Loss: 0.0007\n",
      "Epoch [69/100], Step [110/140], Loss: 0.0003\n",
      "Epoch [69/100], Step [120/140], Loss: 0.4910\n",
      "Epoch [69/100], Step [130/140], Loss: 0.3855\n",
      "Epoch [69/100], Step [140/140], Loss: 0.4840\n",
      "Epoch [70/100], Step [10/140], Loss: 0.5824\n",
      "Epoch [70/100], Step [20/140], Loss: 0.0006\n",
      "Epoch [70/100], Step [30/140], Loss: 0.0010\n",
      "Epoch [70/100], Step [40/140], Loss: 0.0003\n",
      "Epoch [70/100], Step [50/140], Loss: 0.7540\n",
      "Epoch [70/100], Step [60/140], Loss: 0.1794\n",
      "Epoch [70/100], Step [70/140], Loss: 0.7025\n",
      "Epoch [70/100], Step [80/140], Loss: 0.1165\n",
      "Epoch [70/100], Step [90/140], Loss: 0.0007\n",
      "Epoch [70/100], Step [100/140], Loss: 0.0001\n",
      "Epoch [70/100], Step [110/140], Loss: 0.0009\n",
      "Epoch [70/100], Step [120/140], Loss: 0.7369\n",
      "Epoch [70/100], Step [130/140], Loss: 0.3819\n",
      "Epoch [70/100], Step [140/140], Loss: 0.4896\n",
      "Epoch [71/100], Step [10/140], Loss: 0.3783\n",
      "Epoch [71/100], Step [20/140], Loss: 0.5135\n",
      "Epoch [71/100], Step [30/140], Loss: 0.0019\n",
      "Epoch [71/100], Step [40/140], Loss: 0.7038\n",
      "Epoch [71/100], Step [50/140], Loss: 0.5388\n",
      "Epoch [71/100], Step [60/140], Loss: 0.2627\n",
      "Epoch [71/100], Step [70/140], Loss: 0.0014\n",
      "Epoch [71/100], Step [80/140], Loss: 0.3865\n",
      "Epoch [71/100], Step [90/140], Loss: 0.3934\n",
      "Epoch [71/100], Step [100/140], Loss: 0.6794\n",
      "Epoch [71/100], Step [110/140], Loss: 0.0002\n",
      "Epoch [71/100], Step [120/140], Loss: 0.0006\n",
      "Epoch [71/100], Step [130/140], Loss: 0.0002\n",
      "Epoch [71/100], Step [140/140], Loss: 0.6932\n",
      "Epoch [72/100], Step [10/140], Loss: 0.0005\n",
      "Epoch [72/100], Step [20/140], Loss: 0.1110\n",
      "Epoch [72/100], Step [30/140], Loss: 0.1785\n",
      "Epoch [72/100], Step [40/140], Loss: 0.0004\n",
      "Epoch [72/100], Step [50/140], Loss: 0.0002\n",
      "Epoch [72/100], Step [60/140], Loss: 0.0005\n",
      "Epoch [72/100], Step [70/140], Loss: 0.0004\n",
      "Epoch [72/100], Step [80/140], Loss: 0.1807\n",
      "Epoch [72/100], Step [90/140], Loss: 0.0004\n",
      "Epoch [72/100], Step [100/140], Loss: 0.0003\n",
      "Epoch [72/100], Step [110/140], Loss: 0.0003\n",
      "Epoch [72/100], Step [120/140], Loss: 0.5086\n",
      "Epoch [72/100], Step [130/140], Loss: 0.2743\n",
      "Epoch [72/100], Step [140/140], Loss: 0.0001\n",
      "Epoch [73/100], Step [10/140], Loss: 0.0003\n",
      "Epoch [73/100], Step [20/140], Loss: 0.0004\n",
      "Epoch [73/100], Step [30/140], Loss: 0.5742\n",
      "Epoch [73/100], Step [40/140], Loss: 0.0004\n",
      "Epoch [73/100], Step [50/140], Loss: 0.0006\n",
      "Epoch [73/100], Step [60/140], Loss: 0.0008\n",
      "Epoch [73/100], Step [70/140], Loss: 0.0001\n",
      "Epoch [73/100], Step [80/140], Loss: 0.0006\n",
      "Epoch [73/100], Step [90/140], Loss: 0.0003\n",
      "Epoch [73/100], Step [100/140], Loss: 0.4933\n",
      "Epoch [73/100], Step [110/140], Loss: 0.7555\n",
      "Epoch [73/100], Step [120/140], Loss: 0.3142\n",
      "Epoch [73/100], Step [130/140], Loss: 0.0003\n",
      "Epoch [73/100], Step [140/140], Loss: 0.0007\n",
      "Epoch [74/100], Step [10/140], Loss: 0.3415\n",
      "Epoch [74/100], Step [20/140], Loss: 0.0003\n",
      "Epoch [74/100], Step [30/140], Loss: 0.0002\n",
      "Epoch [74/100], Step [40/140], Loss: 0.2335\n",
      "Epoch [74/100], Step [50/140], Loss: 0.4673\n",
      "Epoch [74/100], Step [60/140], Loss: 0.0004\n",
      "Epoch [74/100], Step [70/140], Loss: 0.3422\n",
      "Epoch [74/100], Step [80/140], Loss: 0.0003\n",
      "Epoch [74/100], Step [90/140], Loss: 0.0001\n",
      "Epoch [74/100], Step [100/140], Loss: 0.0006\n",
      "Epoch [74/100], Step [110/140], Loss: 0.0002\n",
      "Epoch [74/100], Step [120/140], Loss: 0.0003\n",
      "Epoch [74/100], Step [130/140], Loss: 0.0004\n",
      "Epoch [74/100], Step [140/140], Loss: 0.5367\n",
      "Epoch [75/100], Step [10/140], Loss: 0.4964\n",
      "Epoch [75/100], Step [20/140], Loss: 0.1297\n",
      "Epoch [75/100], Step [30/140], Loss: 0.1830\n",
      "Epoch [75/100], Step [40/140], Loss: 0.0001\n",
      "Epoch [75/100], Step [50/140], Loss: 0.2276\n",
      "Epoch [75/100], Step [60/140], Loss: 0.7033\n",
      "Epoch [75/100], Step [70/140], Loss: 0.2431\n",
      "Epoch [75/100], Step [80/140], Loss: 0.2413\n",
      "Epoch [75/100], Step [90/140], Loss: 0.3337\n",
      "Epoch [75/100], Step [100/140], Loss: 0.0008\n",
      "Epoch [75/100], Step [110/140], Loss: 0.7667\n",
      "Epoch [75/100], Step [120/140], Loss: 0.3490\n",
      "Epoch [75/100], Step [130/140], Loss: 0.0010\n",
      "Epoch [75/100], Step [140/140], Loss: 0.4723\n",
      "Epoch [76/100], Step [10/140], Loss: 0.1810\n",
      "Epoch [76/100], Step [20/140], Loss: 0.4314\n",
      "Epoch [76/100], Step [30/140], Loss: 0.0003\n",
      "Epoch [76/100], Step [40/140], Loss: 0.0017\n",
      "Epoch [76/100], Step [50/140], Loss: 0.0003\n",
      "Epoch [76/100], Step [60/140], Loss: 0.0006\n",
      "Epoch [76/100], Step [70/140], Loss: 0.0009\n",
      "Epoch [76/100], Step [80/140], Loss: 0.2607\n",
      "Epoch [76/100], Step [90/140], Loss: 0.2467\n",
      "Epoch [76/100], Step [100/140], Loss: 0.0001\n",
      "Epoch [76/100], Step [110/140], Loss: 0.0004\n",
      "Epoch [76/100], Step [120/140], Loss: 0.0903\n",
      "Epoch [76/100], Step [130/140], Loss: 0.0002\n",
      "Epoch [76/100], Step [140/140], Loss: 0.0002\n",
      "Epoch [77/100], Step [10/140], Loss: 0.1210\n",
      "Epoch [77/100], Step [20/140], Loss: 0.3334\n",
      "Epoch [77/100], Step [30/140], Loss: 0.0012\n",
      "Epoch [77/100], Step [40/140], Loss: 0.0002\n",
      "Epoch [77/100], Step [50/140], Loss: 0.0005\n",
      "Epoch [77/100], Step [60/140], Loss: 0.6945\n",
      "Epoch [77/100], Step [70/140], Loss: 0.0002\n",
      "Epoch [77/100], Step [80/140], Loss: 0.0004\n",
      "Epoch [77/100], Step [90/140], Loss: 0.6401\n",
      "Epoch [77/100], Step [100/140], Loss: 0.0004\n",
      "Epoch [77/100], Step [110/140], Loss: 0.3838\n",
      "Epoch [77/100], Step [120/140], Loss: 0.4918\n",
      "Epoch [77/100], Step [130/140], Loss: 0.1044\n",
      "Epoch [77/100], Step [140/140], Loss: 0.0002\n",
      "Epoch [78/100], Step [10/140], Loss: 0.0001\n",
      "Epoch [78/100], Step [20/140], Loss: 0.0008\n",
      "Epoch [78/100], Step [30/140], Loss: 0.0004\n",
      "Epoch [78/100], Step [40/140], Loss: 0.7921\n",
      "Epoch [78/100], Step [50/140], Loss: 0.0005\n",
      "Epoch [78/100], Step [60/140], Loss: 0.2034\n",
      "Epoch [78/100], Step [70/140], Loss: 0.6433\n",
      "Epoch [78/100], Step [80/140], Loss: 0.4591\n",
      "Epoch [78/100], Step [90/140], Loss: 0.1056\n",
      "Epoch [78/100], Step [100/140], Loss: 0.0005\n",
      "Epoch [78/100], Step [110/140], Loss: 0.0007\n",
      "Epoch [78/100], Step [120/140], Loss: 0.2815\n",
      "Epoch [78/100], Step [130/140], Loss: 0.3978\n",
      "Epoch [78/100], Step [140/140], Loss: 0.5204\n",
      "Epoch [79/100], Step [10/140], Loss: 0.0003\n",
      "Epoch [79/100], Step [20/140], Loss: 0.0004\n",
      "Epoch [79/100], Step [30/140], Loss: 0.0005\n",
      "Epoch [79/100], Step [40/140], Loss: 0.0011\n",
      "Epoch [79/100], Step [50/140], Loss: 0.0012\n",
      "Epoch [79/100], Step [60/140], Loss: 0.0955\n",
      "Epoch [79/100], Step [70/140], Loss: 0.0020\n",
      "Epoch [79/100], Step [80/140], Loss: 0.6269\n",
      "Epoch [79/100], Step [90/140], Loss: 0.0005\n",
      "Epoch [79/100], Step [100/140], Loss: 0.0003\n",
      "Epoch [79/100], Step [110/140], Loss: 0.0006\n",
      "Epoch [79/100], Step [120/140], Loss: 0.3171\n",
      "Epoch [79/100], Step [130/140], Loss: 0.0002\n",
      "Epoch [79/100], Step [140/140], Loss: 0.4921\n",
      "Epoch [80/100], Step [10/140], Loss: 0.0019\n",
      "Epoch [80/100], Step [20/140], Loss: 0.0001\n",
      "Epoch [80/100], Step [30/140], Loss: 0.0002\n",
      "Epoch [80/100], Step [40/140], Loss: 0.0004\n",
      "Epoch [80/100], Step [50/140], Loss: 0.0000\n",
      "Epoch [80/100], Step [60/140], Loss: 0.0001\n",
      "Epoch [80/100], Step [70/140], Loss: 0.0003\n",
      "Epoch [80/100], Step [80/140], Loss: 0.6370\n",
      "Epoch [80/100], Step [90/140], Loss: 0.1815\n",
      "Epoch [80/100], Step [100/140], Loss: 0.0001\n",
      "Epoch [80/100], Step [110/140], Loss: 0.0002\n",
      "Epoch [80/100], Step [120/140], Loss: 0.2831\n",
      "Epoch [80/100], Step [130/140], Loss: 0.6698\n",
      "Epoch [80/100], Step [140/140], Loss: 0.0013\n",
      "Epoch [81/100], Step [10/140], Loss: 0.6129\n",
      "Epoch [81/100], Step [20/140], Loss: 0.0002\n",
      "Epoch [81/100], Step [30/140], Loss: 0.0002\n",
      "Epoch [81/100], Step [40/140], Loss: 0.4121\n",
      "Epoch [81/100], Step [50/140], Loss: 0.0002\n",
      "Epoch [81/100], Step [60/140], Loss: 0.0005\n",
      "Epoch [81/100], Step [70/140], Loss: 0.2001\n",
      "Epoch [81/100], Step [80/140], Loss: 0.0005\n",
      "Epoch [81/100], Step [90/140], Loss: 0.0005\n",
      "Epoch [81/100], Step [100/140], Loss: 0.0008\n",
      "Epoch [81/100], Step [110/140], Loss: 0.0001\n",
      "Epoch [81/100], Step [120/140], Loss: 0.0001\n",
      "Epoch [81/100], Step [130/140], Loss: 0.1767\n",
      "Epoch [81/100], Step [140/140], Loss: 0.4155\n",
      "Epoch [82/100], Step [10/140], Loss: 0.0004\n",
      "Epoch [82/100], Step [20/140], Loss: 0.3530\n",
      "Epoch [82/100], Step [30/140], Loss: 0.0003\n",
      "Epoch [82/100], Step [40/140], Loss: 0.0003\n",
      "Epoch [82/100], Step [50/140], Loss: 0.0008\n",
      "Epoch [82/100], Step [60/140], Loss: 0.0006\n",
      "Epoch [82/100], Step [70/140], Loss: 0.0923\n",
      "Epoch [82/100], Step [80/140], Loss: 0.0003\n",
      "Epoch [82/100], Step [90/140], Loss: 0.0005\n",
      "Epoch [82/100], Step [100/140], Loss: 0.0002\n",
      "Epoch [82/100], Step [110/140], Loss: 0.0010\n",
      "Epoch [82/100], Step [120/140], Loss: 0.0001\n",
      "Epoch [82/100], Step [130/140], Loss: 0.0002\n",
      "Epoch [82/100], Step [140/140], Loss: 0.1782\n",
      "Epoch [83/100], Step [10/140], Loss: 0.0002\n",
      "Epoch [83/100], Step [20/140], Loss: 0.5237\n",
      "Epoch [83/100], Step [30/140], Loss: 0.1426\n",
      "Epoch [83/100], Step [40/140], Loss: 0.3159\n",
      "Epoch [83/100], Step [50/140], Loss: 0.7021\n",
      "Epoch [83/100], Step [60/140], Loss: 0.0007\n",
      "Epoch [83/100], Step [70/140], Loss: 0.0007\n",
      "Epoch [83/100], Step [80/140], Loss: 0.0001\n",
      "Epoch [83/100], Step [90/140], Loss: 0.2067\n",
      "Epoch [83/100], Step [100/140], Loss: 0.7169\n",
      "Epoch [83/100], Step [110/140], Loss: 0.0002\n",
      "Epoch [83/100], Step [120/140], Loss: 0.0003\n",
      "Epoch [83/100], Step [130/140], Loss: 0.4207\n",
      "Epoch [83/100], Step [140/140], Loss: 0.7339\n",
      "Epoch [84/100], Step [10/140], Loss: 0.0005\n",
      "Epoch [84/100], Step [20/140], Loss: 0.0005\n",
      "Epoch [84/100], Step [30/140], Loss: 0.0015\n",
      "Epoch [84/100], Step [40/140], Loss: 0.0006\n",
      "Epoch [84/100], Step [50/140], Loss: 0.0003\n",
      "Epoch [84/100], Step [60/140], Loss: 0.1692\n",
      "Epoch [84/100], Step [70/140], Loss: 0.5264\n",
      "Epoch [84/100], Step [80/140], Loss: 0.0004\n",
      "Epoch [84/100], Step [90/140], Loss: 0.0008\n",
      "Epoch [84/100], Step [100/140], Loss: 0.0002\n",
      "Epoch [84/100], Step [110/140], Loss: 0.0007\n",
      "Epoch [84/100], Step [120/140], Loss: 0.0005\n",
      "Epoch [84/100], Step [130/140], Loss: 0.6050\n",
      "Epoch [84/100], Step [140/140], Loss: 0.0018\n",
      "Epoch [85/100], Step [10/140], Loss: 0.0010\n",
      "Epoch [85/100], Step [20/140], Loss: 0.0002\n",
      "Epoch [85/100], Step [30/140], Loss: 0.0008\n",
      "Epoch [85/100], Step [40/140], Loss: 0.0008\n",
      "Epoch [85/100], Step [50/140], Loss: 0.1123\n",
      "Epoch [85/100], Step [60/140], Loss: 0.6495\n",
      "Epoch [85/100], Step [70/140], Loss: 0.3963\n",
      "Epoch [85/100], Step [80/140], Loss: 0.1875\n",
      "Epoch [85/100], Step [90/140], Loss: 0.4670\n",
      "Epoch [85/100], Step [100/140], Loss: 0.0001\n",
      "Epoch [85/100], Step [110/140], Loss: 0.0005\n",
      "Epoch [85/100], Step [120/140], Loss: 0.3688\n",
      "Epoch [85/100], Step [130/140], Loss: 0.2601\n",
      "Epoch [85/100], Step [140/140], Loss: 0.0003\n",
      "Epoch [86/100], Step [10/140], Loss: 0.0005\n",
      "Epoch [86/100], Step [20/140], Loss: 0.0004\n",
      "Epoch [86/100], Step [30/140], Loss: 0.0006\n",
      "Epoch [86/100], Step [40/140], Loss: 0.0000\n",
      "Epoch [86/100], Step [50/140], Loss: 0.0006\n",
      "Epoch [86/100], Step [60/140], Loss: 0.0981\n",
      "Epoch [86/100], Step [70/140], Loss: 0.0001\n",
      "Epoch [86/100], Step [80/140], Loss: 0.0002\n",
      "Epoch [86/100], Step [90/140], Loss: 0.4301\n",
      "Epoch [86/100], Step [100/140], Loss: 0.0002\n",
      "Epoch [86/100], Step [110/140], Loss: 0.0002\n",
      "Epoch [86/100], Step [120/140], Loss: 0.0004\n",
      "Epoch [86/100], Step [130/140], Loss: 0.6861\n",
      "Epoch [86/100], Step [140/140], Loss: 0.0006\n",
      "Epoch [87/100], Step [10/140], Loss: 0.0002\n",
      "Epoch [87/100], Step [20/140], Loss: 0.0003\n",
      "Epoch [87/100], Step [30/140], Loss: 0.0007\n",
      "Epoch [87/100], Step [40/140], Loss: 0.0003\n",
      "Epoch [87/100], Step [50/140], Loss: 0.0002\n",
      "Epoch [87/100], Step [60/140], Loss: 0.5273\n",
      "Epoch [87/100], Step [70/140], Loss: 0.4183\n",
      "Epoch [87/100], Step [80/140], Loss: 0.0005\n",
      "Epoch [87/100], Step [90/140], Loss: 0.4590\n",
      "Epoch [87/100], Step [100/140], Loss: 0.0001\n",
      "Epoch [87/100], Step [110/140], Loss: 0.0004\n",
      "Epoch [87/100], Step [120/140], Loss: 0.2538\n",
      "Epoch [87/100], Step [130/140], Loss: 0.0001\n",
      "Epoch [87/100], Step [140/140], Loss: 0.0001\n",
      "Epoch [88/100], Step [10/140], Loss: 0.1301\n",
      "Epoch [88/100], Step [20/140], Loss: 0.0008\n",
      "Epoch [88/100], Step [30/140], Loss: 0.0003\n",
      "Epoch [88/100], Step [40/140], Loss: 0.4419\n",
      "Epoch [88/100], Step [50/140], Loss: 0.5286\n",
      "Epoch [88/100], Step [60/140], Loss: 0.0002\n",
      "Epoch [88/100], Step [70/140], Loss: 0.1027\n",
      "Epoch [88/100], Step [80/140], Loss: 0.0004\n",
      "Epoch [88/100], Step [90/140], Loss: 0.0005\n",
      "Epoch [88/100], Step [100/140], Loss: 0.0008\n",
      "Epoch [88/100], Step [110/140], Loss: 0.0002\n",
      "Epoch [88/100], Step [120/140], Loss: 0.0002\n",
      "Epoch [88/100], Step [130/140], Loss: 0.0007\n",
      "Epoch [88/100], Step [140/140], Loss: 0.0001\n",
      "Epoch [89/100], Step [10/140], Loss: 0.0005\n",
      "Epoch [89/100], Step [20/140], Loss: 0.1591\n",
      "Epoch [89/100], Step [30/140], Loss: 0.0002\n",
      "Epoch [89/100], Step [40/140], Loss: 0.0002\n",
      "Epoch [89/100], Step [50/140], Loss: 0.0001\n",
      "Epoch [89/100], Step [60/140], Loss: 0.0019\n",
      "Epoch [89/100], Step [70/140], Loss: 0.0006\n",
      "Epoch [89/100], Step [80/140], Loss: 0.6886\n",
      "Epoch [89/100], Step [90/140], Loss: 0.6496\n",
      "Epoch [89/100], Step [100/140], Loss: 0.4651\n",
      "Epoch [89/100], Step [110/140], Loss: 0.0002\n",
      "Epoch [89/100], Step [120/140], Loss: 0.1891\n",
      "Epoch [89/100], Step [130/140], Loss: 0.0003\n",
      "Epoch [89/100], Step [140/140], Loss: 0.0004\n",
      "Epoch [90/100], Step [10/140], Loss: 0.1107\n",
      "Epoch [90/100], Step [20/140], Loss: 0.0001\n",
      "Epoch [90/100], Step [30/140], Loss: 0.0001\n",
      "Epoch [90/100], Step [40/140], Loss: 0.4966\n",
      "Epoch [90/100], Step [50/140], Loss: 0.2780\n",
      "Epoch [90/100], Step [60/140], Loss: 0.0007\n",
      "Epoch [90/100], Step [70/140], Loss: 0.6713\n",
      "Epoch [90/100], Step [80/140], Loss: 0.3808\n",
      "Epoch [90/100], Step [90/140], Loss: 0.0003\n",
      "Epoch [90/100], Step [100/140], Loss: 0.0007\n",
      "Epoch [90/100], Step [110/140], Loss: 0.3554\n",
      "Epoch [90/100], Step [120/140], Loss: 0.0001\n",
      "Epoch [90/100], Step [130/140], Loss: 0.7443\n",
      "Epoch [90/100], Step [140/140], Loss: 0.0006\n",
      "Epoch [91/100], Step [10/140], Loss: 0.0002\n",
      "Epoch [91/100], Step [20/140], Loss: 0.0004\n",
      "Epoch [91/100], Step [30/140], Loss: 0.0002\n",
      "Epoch [91/100], Step [40/140], Loss: 0.1101\n",
      "Epoch [91/100], Step [50/140], Loss: 0.6786\n",
      "Epoch [91/100], Step [60/140], Loss: 0.1431\n",
      "Epoch [91/100], Step [70/140], Loss: 0.3044\n",
      "Epoch [91/100], Step [80/140], Loss: 0.0001\n",
      "Epoch [91/100], Step [90/140], Loss: 0.3492\n",
      "Epoch [91/100], Step [100/140], Loss: 0.5667\n",
      "Epoch [91/100], Step [110/140], Loss: 0.3531\n",
      "Epoch [91/100], Step [120/140], Loss: 0.0000\n",
      "Epoch [91/100], Step [130/140], Loss: 0.0001\n",
      "Epoch [91/100], Step [140/140], Loss: 0.0002\n",
      "Epoch [92/100], Step [10/140], Loss: 0.4931\n",
      "Epoch [92/100], Step [20/140], Loss: 0.0003\n",
      "Epoch [92/100], Step [30/140], Loss: 0.0001\n",
      "Epoch [92/100], Step [40/140], Loss: 0.4104\n",
      "Epoch [92/100], Step [50/140], Loss: 0.0002\n",
      "Epoch [92/100], Step [60/140], Loss: 0.3364\n",
      "Epoch [92/100], Step [70/140], Loss: 0.1901\n",
      "Epoch [92/100], Step [80/140], Loss: 0.0002\n",
      "Epoch [92/100], Step [90/140], Loss: 0.0003\n",
      "Epoch [92/100], Step [100/140], Loss: 0.0012\n",
      "Epoch [92/100], Step [110/140], Loss: 0.6143\n",
      "Epoch [92/100], Step [120/140], Loss: 0.0010\n",
      "Epoch [92/100], Step [130/140], Loss: 0.7529\n",
      "Epoch [92/100], Step [140/140], Loss: 0.0001\n",
      "Epoch [93/100], Step [10/140], Loss: 0.2907\n",
      "Epoch [93/100], Step [20/140], Loss: 0.0003\n",
      "Epoch [93/100], Step [30/140], Loss: 0.3039\n",
      "Epoch [93/100], Step [40/140], Loss: 0.5270\n",
      "Epoch [93/100], Step [50/140], Loss: 0.0004\n",
      "Epoch [93/100], Step [60/140], Loss: 0.0005\n",
      "Epoch [93/100], Step [70/140], Loss: 0.1848\n",
      "Epoch [93/100], Step [80/140], Loss: 0.0003\n",
      "Epoch [93/100], Step [90/140], Loss: 0.0001\n",
      "Epoch [93/100], Step [100/140], Loss: 0.0008\n",
      "Epoch [93/100], Step [110/140], Loss: 0.7282\n",
      "Epoch [93/100], Step [120/140], Loss: 0.1054\n",
      "Epoch [93/100], Step [130/140], Loss: 0.5733\n",
      "Epoch [93/100], Step [140/140], Loss: 0.0001\n",
      "Epoch [94/100], Step [10/140], Loss: 0.1775\n",
      "Epoch [94/100], Step [20/140], Loss: 0.4981\n",
      "Epoch [94/100], Step [30/140], Loss: 0.0003\n",
      "Epoch [94/100], Step [40/140], Loss: 0.0006\n",
      "Epoch [94/100], Step [50/140], Loss: 0.0000\n",
      "Epoch [94/100], Step [60/140], Loss: 0.1668\n",
      "Epoch [94/100], Step [70/140], Loss: 0.0000\n",
      "Epoch [94/100], Step [80/140], Loss: 0.5811\n",
      "Epoch [94/100], Step [90/140], Loss: 0.0002\n",
      "Epoch [94/100], Step [100/140], Loss: 0.4665\n",
      "Epoch [94/100], Step [110/140], Loss: 0.0002\n",
      "Epoch [94/100], Step [120/140], Loss: 0.2921\n",
      "Epoch [94/100], Step [130/140], Loss: 0.0001\n",
      "Epoch [94/100], Step [140/140], Loss: 0.6065\n",
      "Epoch [95/100], Step [10/140], Loss: 0.0001\n",
      "Epoch [95/100], Step [20/140], Loss: 0.0001\n",
      "Epoch [95/100], Step [30/140], Loss: 0.0012\n",
      "Epoch [95/100], Step [40/140], Loss: 0.1586\n",
      "Epoch [95/100], Step [50/140], Loss: 0.1242\n",
      "Epoch [95/100], Step [60/140], Loss: 0.0532\n",
      "Epoch [95/100], Step [70/140], Loss: 0.5236\n",
      "Epoch [95/100], Step [80/140], Loss: 0.0006\n",
      "Epoch [95/100], Step [90/140], Loss: 0.3676\n",
      "Epoch [95/100], Step [100/140], Loss: 0.6649\n",
      "Epoch [95/100], Step [110/140], Loss: 0.2993\n",
      "Epoch [95/100], Step [120/140], Loss: 0.4733\n",
      "Epoch [95/100], Step [130/140], Loss: 0.0004\n",
      "Epoch [95/100], Step [140/140], Loss: 0.5776\n",
      "Epoch [96/100], Step [10/140], Loss: 0.0003\n",
      "Epoch [96/100], Step [20/140], Loss: 0.6501\n",
      "Epoch [96/100], Step [30/140], Loss: 0.0002\n",
      "Epoch [96/100], Step [40/140], Loss: 0.0003\n",
      "Epoch [96/100], Step [50/140], Loss: 0.1484\n",
      "Epoch [96/100], Step [60/140], Loss: 0.6528\n",
      "Epoch [96/100], Step [70/140], Loss: 0.0003\n",
      "Epoch [96/100], Step [80/140], Loss: 0.1369\n",
      "Epoch [96/100], Step [90/140], Loss: 0.2551\n",
      "Epoch [96/100], Step [100/140], Loss: 0.0005\n",
      "Epoch [96/100], Step [110/140], Loss: 0.0001\n",
      "Epoch [96/100], Step [120/140], Loss: 0.0002\n",
      "Epoch [96/100], Step [130/140], Loss: 0.2546\n",
      "Epoch [96/100], Step [140/140], Loss: 0.0000\n",
      "Epoch [97/100], Step [10/140], Loss: 0.0007\n",
      "Epoch [97/100], Step [20/140], Loss: 0.0002\n",
      "Epoch [97/100], Step [30/140], Loss: 0.0001\n",
      "Epoch [97/100], Step [40/140], Loss: 0.0001\n",
      "Epoch [97/100], Step [50/140], Loss: 0.1156\n",
      "Epoch [97/100], Step [60/140], Loss: 0.0003\n",
      "Epoch [97/100], Step [70/140], Loss: 0.6882\n",
      "Epoch [97/100], Step [80/140], Loss: 0.0002\n",
      "Epoch [97/100], Step [90/140], Loss: 0.0001\n",
      "Epoch [97/100], Step [100/140], Loss: 0.0002\n",
      "Epoch [97/100], Step [110/140], Loss: 0.0000\n",
      "Epoch [97/100], Step [120/140], Loss: 0.1118\n",
      "Epoch [97/100], Step [130/140], Loss: 0.4593\n",
      "Epoch [97/100], Step [140/140], Loss: 0.5122\n",
      "Epoch [98/100], Step [10/140], Loss: 0.1903\n",
      "Epoch [98/100], Step [20/140], Loss: 0.2019\n",
      "Epoch [98/100], Step [30/140], Loss: 0.3226\n",
      "Epoch [98/100], Step [40/140], Loss: 0.0002\n",
      "Epoch [98/100], Step [50/140], Loss: 0.0004\n",
      "Epoch [98/100], Step [60/140], Loss: 0.0027\n",
      "Epoch [98/100], Step [70/140], Loss: 0.4409\n",
      "Epoch [98/100], Step [80/140], Loss: 0.0009\n",
      "Epoch [98/100], Step [90/140], Loss: 0.0003\n",
      "Epoch [98/100], Step [100/140], Loss: 0.0004\n",
      "Epoch [98/100], Step [110/140], Loss: 0.6029\n",
      "Epoch [98/100], Step [120/140], Loss: 0.0016\n",
      "Epoch [98/100], Step [130/140], Loss: 0.0002\n",
      "Epoch [98/100], Step [140/140], Loss: 0.4674\n",
      "Epoch [99/100], Step [10/140], Loss: 0.1768\n",
      "Epoch [99/100], Step [20/140], Loss: 0.3916\n",
      "Epoch [99/100], Step [30/140], Loss: 0.3244\n",
      "Epoch [99/100], Step [40/140], Loss: 0.1164\n",
      "Epoch [99/100], Step [50/140], Loss: 0.0003\n",
      "Epoch [99/100], Step [60/140], Loss: 0.0888\n",
      "Epoch [99/100], Step [70/140], Loss: 0.6457\n",
      "Epoch [99/100], Step [80/140], Loss: 0.4034\n",
      "Epoch [99/100], Step [90/140], Loss: 0.0004\n",
      "Epoch [99/100], Step [100/140], Loss: 0.0003\n",
      "Epoch [99/100], Step [110/140], Loss: 0.0005\n",
      "Epoch [99/100], Step [120/140], Loss: 0.0000\n",
      "Epoch [99/100], Step [130/140], Loss: 0.5181\n",
      "Epoch [99/100], Step [140/140], Loss: 0.3778\n",
      "Epoch [100/100], Step [10/140], Loss: 0.4440\n",
      "Epoch [100/100], Step [20/140], Loss: 0.0003\n",
      "Epoch [100/100], Step [30/140], Loss: 0.0004\n",
      "Epoch [100/100], Step [40/140], Loss: 0.0014\n",
      "Epoch [100/100], Step [50/140], Loss: 0.4378\n",
      "Epoch [100/100], Step [60/140], Loss: 0.0006\n",
      "Epoch [100/100], Step [70/140], Loss: 0.4658\n",
      "Epoch [100/100], Step [80/140], Loss: 0.3225\n",
      "Epoch [100/100], Step [90/140], Loss: 0.0006\n",
      "Epoch [100/100], Step [100/140], Loss: 0.0012\n",
      "Epoch [100/100], Step [110/140], Loss: 0.0006\n",
      "Epoch [100/100], Step [120/140], Loss: 0.3768\n",
      "Epoch [100/100], Step [130/140], Loss: 0.0002\n",
      "Epoch [100/100], Step [140/140], Loss: 0.0002\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T06:07:57.876026Z",
     "start_time": "2025-07-14T06:07:57.817341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "\n",
    "\n",
    "def generate_text(context, step, temperature=0.8):\n",
    "    words = [word for word in context]\n",
    "    hidden = None\n",
    "    for _ in range(step):\n",
    "        input_seq = torch.tensor([word_to_index[word] for word in words[-1:]])\n",
    "        input_seq = torch.LongTensor(input_seq)\n",
    "        input_seq = input_seq.view(1, -1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hidden = model(input_seq, hidden)\n",
    "            last_output = output[0, -1, :]\n",
    "            probs = torch.softmax(last_output / temperature, dim=-1)\n",
    "            result_index = torch.multinomial(probs, 1).item()\n",
    "            result = index_to_word[result_index]\n",
    "            words.append(result)\n",
    "    return ''.join(words)\n",
    "\n",
    "\n",
    "print(generate_text('臣密言：', 5, 0.1))"
   ],
   "id": "6b7e5c811c15551c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "臣密言：臣以险衅，\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
