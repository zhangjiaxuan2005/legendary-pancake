{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 文本分类",
   "id": "1c2c25ed569b037c"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "from modelscope.msdatasets import MsDataset\n",
    "\n",
    "ds_train = MsDataset.load('DAMO_NLP/jd', subset_name='default', split='train')\n",
    "ds_test = MsDataset.load('DAMO_NLP/jd', subset_name='default', split='validation')"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 文本向量化",
   "id": "4129efad9fc0a7b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "\n",
    "model_id = \"iic/nlp_corom_sentence-embedding_chinese-base-ecom\"\n",
    "pipeline_se = pipeline(Tasks.sentence_embedding, model=model_id)\n"
   ],
   "id": "38be9900f89a3d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T07:11:25.251121Z",
     "start_time": "2025-07-09T07:11:24.649021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "ds_train_torch = ds_train.to_torch_dataset()\n",
    "\n",
    "ds_train_torch = ds_train_torch.filter(\n",
    "    lambda x: isinstance(x['sentence'], str) and x['label'] is not None and not math.isnan(x['label']))"
   ],
   "id": "4acd5ffe6f181c",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmath\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m ds_train_torch = ds_train.to_torch_dataset()\n\u001B[32m      5\u001B[39m ds_train_torch = ds_train_torch.filter(\n\u001B[32m      6\u001B[39m     \u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;28misinstance\u001B[39m(x[\u001B[33m'\u001B[39m\u001B[33msentence\u001B[39m\u001B[33m'\u001B[39m], \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m x[\u001B[33m'\u001B[39m\u001B[33mlabel\u001B[39m\u001B[33m'\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m math.isnan(x[\u001B[33m'\u001B[39m\u001B[33mlabel\u001B[39m\u001B[33m'\u001B[39m]))\n",
      "\u001B[31mNameError\u001B[39m: name 'ds_train' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# inputs = {\n",
    "#     'source_sentence': ds_train_torch['sentence']\n",
    "# }\n",
    "# ds_train_x = pipeline_se(inputs)"
   ],
   "id": "8064a6b2d054cbf4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, ds_train_torch):\n",
    "        self.ds_train_torch = ds_train_torch\n",
    "        self.pipeline_se = pipeline_se\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds_train_torch['sentence'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentences = self.ds_train_torch['sentence'][idx]\n",
    "        if not isinstance(sentences, list):\n",
    "            sentences = [sentences]\n",
    "        labels = self.ds_train_torch['label'][idx]\n",
    "        outputs = self.pipeline_se(input={'source_sentence': sentences})\n",
    "        embeddings = outputs['text_embedding']\n",
    "        return embeddings, labels\n",
    "\n",
    "train_dataset = MyDataset(ds_train_torch[:500])"
   ],
   "id": "6eff5e9e855c7251",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 模型构建",
   "id": "e426fa634b2c1133"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ],
   "id": "c1925122493d3ba6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 模型训练",
   "id": "adedb40972ea9117"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "model = MyModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.view(inputs.shape[0], -1)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 50 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Step [{i+50}/{len(train_loader)}], Loss: {loss.item():.4f}')"
   ],
   "id": "f5b0c69411700f5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 测试",
   "id": "56176a9ae6ca05a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "\n",
    "ds_test_torch = ds_test.to_torch_dataset()\n",
    "\n",
    "ds_test_torch = ds_test_torch.filter(lambda x: isinstance(x['sentence'], str) and x['label'] is not None and not math.isnan(x['label']))\n",
    "\n",
    "test_dataset = MyDataset(ds_test_torch[:100])\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.view(inputs.shape[0], -1)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        match=(predicted == labels)\n",
    "        correct += match.sum().item()\n",
    "    print(f'Accuracy of the network on the {total} test images: {100 * correct / total}%')"
   ],
   "id": "d640b99b7764af3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### GPU 版本",
   "id": "f402a3393da4e5e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import math\n",
    "import torch\n",
    "from modelscope.msdatasets import MsDataset\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "ds_train = MsDataset.load('DAMO_NLP/jd', subset_name='default', split='train')\n",
    "ds_test = MsDataset.load('DAMO_NLP/jd', subset_name='default', split='validation')\n",
    "\n",
    "ds_train_torch = ds_train.to_torch_dataset()\n",
    "ds_train_torch = ds_train_torch.filter(\n",
    "    lambda x: isinstance(x['sentence'], str) and x['label'] is not None and not math.isnan(x['label']))\n",
    "ds_test_torch = ds_test.to_torch_dataset()\n",
    "ds_test_torch = ds_test_torch.filter(\n",
    "    lambda x: isinstance(x['sentence'], str) and x['label'] is not None and not math.isnan(x['label']))\n",
    "\n",
    "model_id = \"iic/nlp_corom_sentence-embedding_chinese-base-ecom\"\n",
    "pipeline_se = pipeline(Tasks.sentence_embedding, model=model_id)\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, ds_train_torch):\n",
    "        self.ds_train_torch = ds_train_torch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds_train_torch['sentence'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.ds_train_torch['sentence'][idx], self.ds_train_torch['label'][idx]\n",
    "\n",
    "\n",
    "train_dataset = MyDataset(ds_train_torch[:2000])\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sentences, labels = zip(*batch)\n",
    "\n",
    "    output = pipeline_se(input={'source_sentence': list(sentences)})\n",
    "    embeddings = output['text_embedding']\n",
    "\n",
    "    embeddings = torch.tensor(embeddings)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    return embeddings, labels\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MyModel()\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.view(inputs.shape[0], -1)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 50 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Step [{i + 50}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "test_dataset = MyDataset(ds_test_torch[:100])\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        inputs = inputs.view(inputs.shape[0], -1)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        match = (predicted == labels)\n",
    "        correct += match.sum().item()\n",
    "    print(f'Accuracy of the network on the {total} test images: {100 * correct / total}%')"
   ],
   "id": "4b1275ab63a8b36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T13:39:35.846620Z",
     "start_time": "2025-07-08T13:38:23.293449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import torch\n",
    "from modelscope.msdatasets import MsDataset\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "ds_train = MsDataset.load('DAMO_NLP/jd', subset_name='default', split='train')\n",
    "ds_test = MsDataset.load('DAMO_NLP/jd', subset_name='default', split='validation')\n",
    "\n",
    "ds_train_torch = ds_train.to_torch_dataset()\n",
    "ds_train_torch = ds_train_torch.filter(\n",
    "    lambda x: isinstance(x['sentence'], str) and x['label'] is not None and not math.isnan(x['label']))\n",
    "ds_test_torch = ds_test.to_torch_dataset()\n",
    "ds_test_torch = ds_test_torch.filter(\n",
    "    lambda x: isinstance(x['sentence'], str) and x['label'] is not None and not math.isnan(x['label']))\n",
    "\n",
    "model_id = \"iic/nlp_corom_sentence-embedding_chinese-base-ecom\"\n",
    "pipeline_se = pipeline(Tasks.sentence_embedding, model=model_id)\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, ds_train_torch):\n",
    "        self.ds_train_torch = ds_train_torch\n",
    "        self.sentence = ds_train_torch['sentence']\n",
    "        self.label = ds_train_torch['label']\n",
    "    def __len__(self):\n",
    "        return len(self.ds_train_torch['sentence'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sentence[idx], self.label[idx]\n",
    "\n",
    "\n",
    "train_dataset = MyDataset(ds_train_torch)\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sentences, labels = zip(*batch)\n",
    "\n",
    "    output = pipeline_se(input={'source_sentence': list(sentences)})\n",
    "    embeddings = output['text_embedding']\n",
    "\n",
    "    embeddings = torch.tensor(embeddings)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    return embeddings, labels\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MyModel()\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.view(inputs.shape[0], -1)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 50 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Step [{i + 50}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "test_dataset = MyDataset(ds_test_torch[:100])\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        inputs = inputs.view(inputs.shape[0], -1)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        match = (predicted == labels)\n",
    "        correct += match.sum().item()\n",
    "    print(f'Accuracy of the network on the {total} test images: {100 * correct / total}%')"
   ],
   "id": "3aab004640705acd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17246\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-07-08 21:38:31,447 - modelscope - WARNING - Use trust_remote_code=True. Will invoke codes from jd. Please make sure that you can trust the external codes.\n",
      "2025-07-08 21:38:33,113 - modelscope - WARNING - Reusing dataset dataset_builder (C:\\Users\\17246\\.cache\\modelscope\\hub\\datasets\\DAMO_NLP\\jd\\master\\data_files)\n",
      "2025-07-08 21:38:33,115 - modelscope - INFO - Generating dataset dataset_builder (C:\\Users\\17246\\.cache\\modelscope\\hub\\datasets\\DAMO_NLP\\jd\\master\\data_files)\n",
      "2025-07-08 21:38:33,115 - modelscope - INFO - Reusing cached meta-data file: C:\\Users\\17246\\.cache\\modelscope\\hub\\datasets\\DAMO_NLP\\jd\\master\\data_files\\3a0b7ca43b11a413d66fb247f31fb16f\n",
      "2025-07-08 21:38:33,519 - modelscope - WARNING - Use trust_remote_code=True. Will invoke codes from jd. Please make sure that you can trust the external codes.\n",
      "2025-07-08 21:38:35,093 - modelscope - WARNING - Reusing dataset dataset_builder (C:\\Users\\17246\\.cache\\modelscope\\hub\\datasets\\DAMO_NLP\\jd\\master\\data_files)\n",
      "2025-07-08 21:38:35,093 - modelscope - INFO - Generating dataset dataset_builder (C:\\Users\\17246\\.cache\\modelscope\\hub\\datasets\\DAMO_NLP\\jd\\master\\data_files)\n",
      "2025-07-08 21:38:35,094 - modelscope - INFO - Reusing cached meta-data file: C:\\Users\\17246\\.cache\\modelscope\\hub\\datasets\\DAMO_NLP\\jd\\master\\data_files\\a6da68b5310a529b1be5166a6d78da55\n",
      "Filter: 100%|██████████| 45366/45366 [00:00<00:00, 63666.63 examples/s]\n",
      "Filter: 100%|██████████| 5032/5032 [00:00<00:00, 55840.16 examples/s]\n",
      "2025-07-08 21:38:37,051 - modelscope - WARNING - Model revision not specified, use revision: v1.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: C:\\Users\\17246\\.cache\\modelscope\\hub\\models\\iic\\nlp_corom_sentence-embedding_chinese-base-ecom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-08 21:38:38,595 - modelscope - WARNING - Model revision not specified, use revision: v1.0.0\n",
      "2025-07-08 21:38:38,915 - modelscope - INFO - initiate model from C:\\Users\\17246\\.cache\\modelscope\\hub\\models\\iic\\nlp_corom_sentence-embedding_chinese-base-ecom\n",
      "2025-07-08 21:38:38,916 - modelscope - INFO - initiate model from location C:\\Users\\17246\\.cache\\modelscope\\hub\\models\\iic\\nlp_corom_sentence-embedding_chinese-base-ecom.\n",
      "2025-07-08 21:38:38,922 - modelscope - INFO - initialize model from C:\\Users\\17246\\.cache\\modelscope\\hub\\models\\iic\\nlp_corom_sentence-embedding_chinese-base-ecom\n",
      "2025-07-08 21:38:39,113 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2025-07-08 21:38:39,113 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2025-07-08 21:38:39,114 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'C:\\\\Users\\\\17246\\\\.cache\\\\modelscope\\\\hub\\\\models\\\\iic\\\\nlp_corom_sentence-embedding_chinese-base-ecom'}. trying to build by task and model information.\n",
      "2025-07-08 21:38:39,202 - modelscope - INFO - cuda is not available, using cpu instead.\n",
      "2025-07-08 21:38:39,210 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2025-07-08 21:38:39,211 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2025-07-08 21:38:39,211 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'C:\\\\Users\\\\17246\\\\.cache\\\\modelscope\\\\hub\\\\models\\\\iic\\\\nlp_corom_sentence-embedding_chinese-base-ecom', 'sequence_length': 128}. trying to build by task and model information.\n",
      "C:\\Users\\17246\\miniconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:1731: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [50/1407], Loss: 0.7064\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 77\u001B[39m\n\u001B[32m     75\u001B[39m epochs = \u001B[32m100\u001B[39m\n\u001B[32m     76\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[32m---> \u001B[39m\u001B[32m77\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m i, (inputs, labels) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader):\n\u001B[32m     78\u001B[39m         inputs = inputs.to(device)\n\u001B[32m     79\u001B[39m         labels = labels.to(device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    730\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    731\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    732\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m733\u001B[39m data = \u001B[38;5;28mself\u001B[39m._next_data()\n\u001B[32m    734\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    735\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    736\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    737\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    738\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    739\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001B[39m, in \u001B[36m_SingleProcessDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    787\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    788\u001B[39m     index = \u001B[38;5;28mself\u001B[39m._next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m789\u001B[39m     data = \u001B[38;5;28mself\u001B[39m._dataset_fetcher.fetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    790\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pin_memory:\n\u001B[32m    791\u001B[39m         data = _utils.pin_memory.pin_memory(data, \u001B[38;5;28mself\u001B[39m._pin_memory_device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001B[39m, in \u001B[36m_MapDatasetFetcher.fetch\u001B[39m\u001B[34m(self, possibly_batched_index)\u001B[39m\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     54\u001B[39m     data = \u001B[38;5;28mself\u001B[39m.dataset[possibly_batched_index]\n\u001B[32m---> \u001B[39m\u001B[32m55\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.collate_fn(data)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 57\u001B[39m, in \u001B[36mcollate_fn\u001B[39m\u001B[34m(batch)\u001B[39m\n\u001B[32m     54\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcollate_fn\u001B[39m(batch):\n\u001B[32m     55\u001B[39m     sentences, labels = \u001B[38;5;28mzip\u001B[39m(*batch)\n\u001B[32m---> \u001B[39m\u001B[32m57\u001B[39m     output = pipeline_se(\u001B[38;5;28minput\u001B[39m={\u001B[33m'\u001B[39m\u001B[33msource_sentence\u001B[39m\u001B[33m'\u001B[39m: \u001B[38;5;28mlist\u001B[39m(sentences)})\n\u001B[32m     58\u001B[39m     embeddings = output[\u001B[33m'\u001B[39m\u001B[33mtext_embedding\u001B[39m\u001B[33m'\u001B[39m]\n\u001B[32m     60\u001B[39m     embeddings = torch.tensor(embeddings)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\modelscope\\pipelines\\base.py:242\u001B[39m, in \u001B[36mPipeline.__call__\u001B[39m\u001B[34m(self, input, *args, **kwargs)\u001B[39m\n\u001B[32m    239\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._process_iterator(\u001B[38;5;28minput\u001B[39m, *args, **kwargs)\n\u001B[32m    241\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m242\u001B[39m     output = \u001B[38;5;28mself\u001B[39m._process_single(\u001B[38;5;28minput\u001B[39m, *args, **kwargs)\n\u001B[32m    243\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\modelscope\\pipelines\\base.py:277\u001B[39m, in \u001B[36mPipeline._process_single\u001B[39m\u001B[34m(self, input, *args, **kwargs)\u001B[39m\n\u001B[32m    275\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._auto_collate:\n\u001B[32m    276\u001B[39m             out = \u001B[38;5;28mself\u001B[39m._collate_fn(out)\n\u001B[32m--> \u001B[39m\u001B[32m277\u001B[39m         out = \u001B[38;5;28mself\u001B[39m.forward(out, **forward_params)\n\u001B[32m    278\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    279\u001B[39m     out = \u001B[38;5;28mself\u001B[39m.forward(out, **forward_params)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\modelscope\\pipelines\\nlp\\sentence_embedding_pipeline.py:60\u001B[39m, in \u001B[36mSentenceEmbeddingPipeline.forward\u001B[39m\u001B[34m(self, inputs, **forward_params)\u001B[39m\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any],\n\u001B[32m     59\u001B[39m             **forward_params) -> Dict[\u001B[38;5;28mstr\u001B[39m, Any]:\n\u001B[32m---> \u001B[39m\u001B[32m60\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.model(**inputs, **forward_params)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\modelscope\\models\\base\\base_torch_model.py:36\u001B[39m, in \u001B[36mTorchModel.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m     34\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.postprocess(\u001B[38;5;28mself\u001B[39m.forward(args[\u001B[32m0\u001B[39m], **kwargs))\n\u001B[32m     35\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m36\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.postprocess(\u001B[38;5;28mself\u001B[39m.forward(*args, **kwargs))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\modelscope\\models\\nlp\\bert\\sentence_embedding.py:91\u001B[39m, in \u001B[36mBertForSentenceEmbedding.forward\u001B[39m\u001B[34m(self, query, docs, labels)\u001B[39m\n\u001B[32m     89\u001B[39m query_embeddings, doc_embeddings = \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m     90\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m query \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m91\u001B[39m     query_embeddings = \u001B[38;5;28mself\u001B[39m.encode(**query)\n\u001B[32m     92\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m docs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     93\u001B[39m     doc_embeddings = \u001B[38;5;28mself\u001B[39m.encode(**docs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\modelscope\\models\\nlp\\bert\\sentence_embedding.py:122\u001B[39m, in \u001B[36mBertForSentenceEmbedding.encode\u001B[39m\u001B[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001B[39m\n\u001B[32m    110\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mencode\u001B[39m(\n\u001B[32m    111\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    112\u001B[39m     input_ids=\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    120\u001B[39m     return_dict=\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    121\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m122\u001B[39m     outputs = \u001B[38;5;28mself\u001B[39m.base_model.forward(\n\u001B[32m    123\u001B[39m         input_ids,\n\u001B[32m    124\u001B[39m         attention_mask=attention_mask,\n\u001B[32m    125\u001B[39m         token_type_ids=token_type_ids,\n\u001B[32m    126\u001B[39m         position_ids=position_ids,\n\u001B[32m    127\u001B[39m         head_mask=head_mask,\n\u001B[32m    128\u001B[39m         inputs_embeds=inputs_embeds,\n\u001B[32m    129\u001B[39m         output_attentions=output_attentions,\n\u001B[32m    130\u001B[39m         output_hidden_states=output_hidden_states,\n\u001B[32m    131\u001B[39m         return_dict=return_dict)\n\u001B[32m    132\u001B[39m     outputs = \u001B[38;5;28mself\u001B[39m.pooler(outputs, attention_mask)\n\u001B[32m    133\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.normalize:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\modelscope\\models\\nlp\\bert\\backbone.py:901\u001B[39m, in \u001B[36mBertModel.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001B[39m\n\u001B[32m    891\u001B[39m head_mask = \u001B[38;5;28mself\u001B[39m.get_head_mask(head_mask,\n\u001B[32m    892\u001B[39m                                \u001B[38;5;28mself\u001B[39m.config.num_hidden_layers)\n\u001B[32m    894\u001B[39m embedding_output = \u001B[38;5;28mself\u001B[39m.embeddings(\n\u001B[32m    895\u001B[39m     input_ids=input_ids,\n\u001B[32m    896\u001B[39m     position_ids=position_ids,\n\u001B[32m   (...)\u001B[39m\u001B[32m    899\u001B[39m     past_key_values_length=past_key_values_length,\n\u001B[32m    900\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m901\u001B[39m encoder_outputs = \u001B[38;5;28mself\u001B[39m.encoder(\n\u001B[32m    902\u001B[39m     embedding_output,\n\u001B[32m    903\u001B[39m     attention_mask=extended_attention_mask,\n\u001B[32m    904\u001B[39m     head_mask=head_mask,\n\u001B[32m    905\u001B[39m     encoder_hidden_states=encoder_hidden_states,\n\u001B[32m    906\u001B[39m     encoder_attention_mask=encoder_extended_attention_mask,\n\u001B[32m    907\u001B[39m     past_key_values=past_key_values,\n\u001B[32m    908\u001B[39m     use_cache=use_cache,\n\u001B[32m    909\u001B[39m     output_attentions=output_attentions,\n\u001B[32m    910\u001B[39m     output_hidden_states=output_hidden_states,\n\u001B[32m    911\u001B[39m     return_dict=return_dict,\n\u001B[32m    912\u001B[39m )\n\u001B[32m    913\u001B[39m sequence_output = encoder_outputs[\u001B[32m0\u001B[39m]\n\u001B[32m    914\u001B[39m pooled_output = \u001B[38;5;28mself\u001B[39m.pooler(\n\u001B[32m    915\u001B[39m     sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.pooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\modelscope\\models\\nlp\\bert\\backbone.py:530\u001B[39m, in \u001B[36mBertEncoder.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[39m\n\u001B[32m    521\u001B[39m     layer_outputs = torch.utils.checkpoint.checkpoint(\n\u001B[32m    522\u001B[39m         create_custom_forward(layer_module),\n\u001B[32m    523\u001B[39m         hidden_states,\n\u001B[32m   (...)\u001B[39m\u001B[32m    527\u001B[39m         encoder_attention_mask,\n\u001B[32m    528\u001B[39m     )\n\u001B[32m    529\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m530\u001B[39m     layer_outputs = layer_module(\n\u001B[32m    531\u001B[39m         hidden_states,\n\u001B[32m    532\u001B[39m         attention_mask,\n\u001B[32m    533\u001B[39m         layer_head_mask,\n\u001B[32m    534\u001B[39m         encoder_hidden_states,\n\u001B[32m    535\u001B[39m         encoder_attention_mask,\n\u001B[32m    536\u001B[39m         past_key_value,\n\u001B[32m    537\u001B[39m         output_attentions,\n\u001B[32m    538\u001B[39m     )\n\u001B[32m    540\u001B[39m hidden_states = layer_outputs[\u001B[32m0\u001B[39m]\n\u001B[32m    541\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\modelscope\\models\\nlp\\bert\\backbone.py:406\u001B[39m, in \u001B[36mBertLayer.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[39m\n\u001B[32m    393\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\n\u001B[32m    394\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    395\u001B[39m     hidden_states,\n\u001B[32m   (...)\u001B[39m\u001B[32m    402\u001B[39m ):\n\u001B[32m    403\u001B[39m     \u001B[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[39;00m\n\u001B[32m    404\u001B[39m     self_attn_past_key_value = past_key_value[:\n\u001B[32m    405\u001B[39m                                               \u001B[32m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m406\u001B[39m     self_attention_outputs = \u001B[38;5;28mself\u001B[39m.attention(\n\u001B[32m    407\u001B[39m         hidden_states,\n\u001B[32m    408\u001B[39m         attention_mask,\n\u001B[32m    409\u001B[39m         head_mask,\n\u001B[32m    410\u001B[39m         output_attentions=output_attentions,\n\u001B[32m    411\u001B[39m         past_key_value=self_attn_past_key_value,\n\u001B[32m    412\u001B[39m     )\n\u001B[32m    413\u001B[39m     attention_output = self_attention_outputs[\u001B[32m0\u001B[39m]\n\u001B[32m    415\u001B[39m     \u001B[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\modelscope\\models\\nlp\\bert\\backbone.py:327\u001B[39m, in \u001B[36mBertAttention.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[39m\n\u001B[32m    317\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\n\u001B[32m    318\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    319\u001B[39m     hidden_states,\n\u001B[32m   (...)\u001B[39m\u001B[32m    325\u001B[39m     output_attentions=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    326\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m327\u001B[39m     self_outputs = \u001B[38;5;28mself\u001B[39m.self(\n\u001B[32m    328\u001B[39m         hidden_states,\n\u001B[32m    329\u001B[39m         attention_mask,\n\u001B[32m    330\u001B[39m         head_mask,\n\u001B[32m    331\u001B[39m         encoder_hidden_states,\n\u001B[32m    332\u001B[39m         encoder_attention_mask,\n\u001B[32m    333\u001B[39m         past_key_value,\n\u001B[32m    334\u001B[39m         output_attentions,\n\u001B[32m    335\u001B[39m     )\n\u001B[32m    336\u001B[39m     attention_output = \u001B[38;5;28mself\u001B[39m.output(self_outputs[\u001B[32m0\u001B[39m], hidden_states)\n\u001B[32m    337\u001B[39m     outputs = (attention_output,\n\u001B[32m    338\u001B[39m                ) + self_outputs[\u001B[32m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\modelscope\\models\\nlp\\bert\\backbone.py:248\u001B[39m, in \u001B[36mBertSelfAttention.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[39m\n\u001B[32m    245\u001B[39m     attention_scores = attention_scores + attention_mask\n\u001B[32m    247\u001B[39m \u001B[38;5;66;03m# Normalize the attention scores to probabilities.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m248\u001B[39m attention_probs = nn.functional.softmax(attention_scores, dim=-\u001B[32m1\u001B[39m)\n\u001B[32m    250\u001B[39m \u001B[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001B[39;00m\n\u001B[32m    251\u001B[39m \u001B[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001B[39;00m\n\u001B[32m    252\u001B[39m attention_probs = \u001B[38;5;28mself\u001B[39m.dropout(attention_probs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\torch\\nn\\functional.py:2140\u001B[39m, in \u001B[36msoftmax\u001B[39m\u001B[34m(input, dim, _stacklevel, dtype)\u001B[39m\n\u001B[32m   2138\u001B[39m     dim = _get_softmax_dim(\u001B[33m\"\u001B[39m\u001B[33msoftmax\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28minput\u001B[39m.dim(), _stacklevel)\n\u001B[32m   2139\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2140\u001B[39m     ret = \u001B[38;5;28minput\u001B[39m.softmax(dim)\n\u001B[32m   2141\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   2142\u001B[39m     ret = \u001B[38;5;28minput\u001B[39m.softmax(dim, dtype=dtype)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
